{{- if .Values.grafana.enabled -}}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "otel-demo.name" . }}-grafana-dashboards
  labels:
    {{- include "otel-demo.labels" . | nindent 4 }}
data:
  pixie-dashboard.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "DS_PIXIE_GRAFANA DATASOURCE PLUGIN",
          "label": "Pixie Grafana Datasource Plugin",
          "description": "",
          "type": "datasource",
          "pluginId": "pixie-pixie-datasource",
          "pluginName": "Pixie Grafana Datasource Plugin"
        }
      ],
      "__requires": [
        {
          "type": "panel",
          "id": "nodeGraph",
          "name": "Node Graph",
          "version": ""
        },
        {
          "type": "datasource",
          "id": "pixie-pixie-datasource",
          "name": "Pixie Grafana Datasource Plugin",
          "version": "0.0.9"
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1657152736466,
      "links": [],
      "panels": [
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "gridPos": {
            "h": 14,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''\nThis query outputs a graph of the HTTP traffic between the services in\nyour cluster. Use with Grafana's node graph panel.\n\nThis query is for use with Grafana's Pixie Datasource Plugin only,\nas it uses Grafana macros for adding Grafana dashboard context.\nThe functions in this query are pulled from the px/cluster script:\nhttps://github.com/pixie-io/pixie/tree/main/src/pxl_scripts/px/cluster\n'''\n\n# Import Pixie's module for querying data.\nimport px\n\n# Window size to use on time_ column for bucketing.\nns_per_s = 1000 * 1000 * 1000\nns_per_ms = 1000 * 1000\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\n# Hack to get the time window for the script.\n# TODO(philkuz): Replace this with a built-in.\ndef get_time_window(start_time: int):\n    ''' Converts the start_time string into a table with a single column and single row.\n    The approach is hacky, and will round to roughly 1 second.\n    '''\n    df = px.DataFrame('process_stats', start_time=start_time)\n\n    df = df.agg(\n        time_min=('time_', px.min),\n        time_max=('time_', px.max),\n    )\n\n    df.window = px.DurationNanos(df.time_max - df.time_min)\n    df = df[['window']]\n\n    return df\n\n\ndef add_time_window_column(df, start_time):\n    tw = get_time_window(start_time)\n    df = df.merge(tw, how='inner', left_on=[], right_on=[])\n    return df\n\n\ndef process_stats_by_entity(start_time: int, entity: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) per node or pod.\n    Args:\n    @start_time Starting time of the data to examine.\n    @entity: Either pod or node_name.\n    '''\n    # Window size to use on time_ column for bucketing.\n    ns_per_s = 1000 * 1000 * 1000\n    window_ns = px.DurationNanos(10 * ns_per_s)\n\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df[entity] = df.ctx[entity]\n    df.timestamp = px.bin(df.time_, window_ns)\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby([entity, 'upid', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.read_bytes = df.read_bytes_max - df.read_bytes_min\n    df.write_bytes = df.write_bytes_max - df.write_bytes_min\n    df.rchar_bytes = df.rchar_bytes_max - df.rchar_bytes_min\n    df.wchar_bytes = df.wchar_bytes_max - df.wchar_bytes_min\n    # Sum by UPID.\n    df = df.groupby([entity, 'timestamp']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        read_bytes=('read_bytes', px.sum),\n        write_bytes=('write_bytes', px.sum),\n        rchar_bytes=('rchar_bytes', px.sum),\n        wchar_bytes=('wchar_bytes', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n    df.actual_disk_read_throughput = df.read_bytes / window_ns\n    df.actual_disk_write_throughput = df.write_bytes / window_ns\n    df.total_disk_read_throughput = df.rchar_bytes / window_ns\n    df.total_disk_write_throughput = df.wchar_bytes / window_ns\n    # Now take the mean value over the various timestamps.\n    df = df.groupby(entity).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.mean),\n        cpu_utime_ns=('cpu_utime_ns', px.mean),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.mean),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.mean),\n        total_disk_read_throughput=('total_disk_read_throughput', px.mean),\n        total_disk_write_throughput=('total_disk_write_throughput', px.mean),\n        avg_rss=('rss', px.mean),\n        avg_vsize=('vsize', px.mean),\n    )\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns'])\n\n\ndef nodes_for_cluster(start_time: int):\n    ''' Gets a list of nodes in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.node = df.ctx['node_name']\n    df.pod = df.ctx['pod_name']\n    agg = df.groupby(['node', 'pod']).agg()\n    nodes = agg.groupby('node').agg(pod_count=('pod', px.count))\n    process_stats = process_stats_by_entity(start_time, 'node')\n    output = process_stats.merge(nodes, how='inner', left_on='node', right_on='node',\n                                 suffixes=['', '_x'])\n    return output[['node', 'cpu_usage', 'pod_count']]\n\n\ndef pods_for_cluster(start_time: int):\n    ''' A list of pods in 'namespace'.\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The name of the namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.pod = df.ctx['pod_name']\n    df.node = df.ctx['node_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'node', 'container']).agg()\n    df = df.groupby(['pod', 'node']).agg(container_count=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    process_stats = process_stats_by_entity(start_time, 'pod')\n    output = process_stats.merge(df, how='inner', left_on='pod', right_on='pod',\n                                 suffixes=['', '_x'])\n    return output[['pod', 'cpu_usage', 'total_disk_read_throughput',\n                   'total_disk_write_throughput', 'container_count',\n                   'node', 'start_time', 'status']]\n\n\ndef namespaces_for_cluster(start_time: int):\n    ''' Gets a overview of namespaces in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service_name']\n    df.pod = df.ctx['pod_name']\n    df.namespace = df.ctx['namespace']\n    agg = df.groupby(['service', 'pod', 'namespace']).agg()\n    pod_count = agg.groupby(['namespace', 'pod']).agg()\n    pod_count = pod_count.groupby('namespace').agg(pod_count=('pod', px.count))\n    svc_count = agg.groupby(['namespace', 'service']).agg()\n    svc_count = svc_count.groupby('namespace').agg(service_count=('service', px.count))\n    pod_and_svc_count = pod_count.merge(svc_count, how='inner',\n                                        left_on='namespace', right_on='namespace',\n                                        suffixes=['', '_x'])\n    process_stats = process_stats_by_entity(start_time, 'namespace')\n    output = process_stats.merge(pod_and_svc_count, how='inner', left_on='namespace',\n                                 right_on='namespace', suffixes=['', '_y'])\n    return output[['namespace', 'pod_count', 'service_count', 'avg_vsize', 'avg_rss']]\n\n\ndef services_for_cluster(start_time: int):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = service_let_summary(start_time)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef http_stats(start_time: int):\n    ''' Get a dataframe of HTTP events.\n    Certain traffic (like health checks) are auto removed, and some standard fields are added.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n\n    # Add K8s metadata.\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n\n    # Filter out non-k8s entities.\n    df = df[df.pod != '']\n\n    # Additional HTTP fields, pre-computed for convenience.\n    df.failure = df.resp_status >= 400\n\n    # Remove health checks, and anything with no remote address.\n    health_check_req = ((df.req_path == '/healthz' or df.req_path == '/readyz') or df.req_path == '/livez')\n    filter_out_conds = (health_check_req and filter_health_checks) or (df['remote_addr'] == '-')\n    df = df[not filter_out_conds]\n\n    return df\n\n\ndef http_stats_by_service(start_time: int):\n    ''' Get a data frame of HTTP stats per service. The HTTP stats are for inbound traffic,\n    and includes HTTP request count, error count and latency quantiles.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n\n    # Compute HTTP metrics.\n    df = df.groupby(['service']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        http_latency_in=('latency', px.quantiles)\n    )\n\n    return df\n\n\ndef conn_stats(start_time: int):\n    ''' Get a dataframe of connection stats.\n    For each client-server pair, the resulting data frame has the bytes sent and received.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='conn_stats', start_time=start_time)\n\n    df.pod = df.ctx['pod']\n    df.service = df.ctx['service']\n\n    df = df[df.service != '']\n\n    # Find min/max bytes transferred over the selected time window per pod.\n    df = df.groupby(['upid', 'remote_addr', 'remote_port', 'pod', 'service', 'trace_role']).agg(\n        bytes_recv_min=('bytes_recv', px.min),\n        bytes_recv_max=('bytes_recv', px.max),\n        bytes_sent_min=('bytes_sent', px.min),\n        bytes_sent_max=('bytes_sent', px.max),\n    )\n\n    # Calculate bytes transferred over the time window\n    df.bytes_sent = df.bytes_sent_max - df.bytes_sent_min\n    df.bytes_recv = df.bytes_recv_max - df.bytes_recv_min\n    df = df.drop(['bytes_recv_min', 'bytes_recv_max', 'bytes_sent_min', 'bytes_sent_max'])\n\n    return df\n\n\ndef conn_stats_by_service(start_time: int):\n    ''' Get a dataframe of connection stats aggregated by service.\n    For each service, the resulting data frame contains rx/tx stats for server-side and client-side connections.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = conn_stats(start_time)\n\n    # Group by service and trace role.\n    # Do this after computing bytes sent/received by conn_stats key ({upid, remote_addr, remote_port}).\n    # Keeping trace_role allows us to see which traffic was part of server duties vs client duties.\n    df = df.groupby(['service', 'trace_role']).agg(\n        bytes_recv=('bytes_recv', px.sum),\n        bytes_sent=('bytes_sent', px.sum),\n    )\n\n    # Get RX/TX stats for the server side connections.\n    server_df = df[df.trace_role == 2]\n    server_df.rx_server = server_df.bytes_recv\n    server_df.tx_server = server_df.bytes_sent\n    server_df = server_df[['service', 'rx_server', 'tx_server']]\n\n    # Get RX/TX stats for the client side connections.\n    client_df = df[df.trace_role == 1]\n    client_df.rx_client = client_df.bytes_recv\n    client_df.tx_client = client_df.bytes_sent\n    client_df = client_df[['service', 'rx_client', 'tx_client']]\n\n    # Create a dataframe that contains both server-side and client-side RX/TX stats.\n    df = server_df.merge(client_df,\n                         how='left',\n                         left_on='service',\n                         right_on='service',\n                         suffixes=['', '_x'])\n    df = df['service', 'rx_server', 'tx_server', 'rx_client', 'tx_client']\n\n    return df\n\n\ndef service_let_summary(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests\n        on services in the current cluster..\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    conn_stats_df = conn_stats_by_service(start_time)\n    http_stats_df = http_stats_by_service(start_time)\n\n    # Merge conn_stats_df and http_stats_df.\n    df = conn_stats_df.merge(http_stats_df,\n                             how='left',\n                             left_on='service',\n                             right_on='service',\n                             suffixes=['', '_x'])\n\n    # Compute time window for the query and add it as a column.\n    df = add_time_window_column(df, start_time)\n\n    # Compute throughput values.\n    df.http_req_throughput_in = df.http_req_count_in / df.window\n    df.http_error_rate_in = px.Percent(\n        px.select(df.http_req_count_in != 0, df.http_error_count_in / df.http_req_count_in, 0.0))\n    df.inbound_conns = (df.rx_server + df.tx_server) / df.window\n    df.outbound_conns = (df.tx_client + df.rx_client) / df.window\n\n    return df[['service', 'http_latency_in', 'http_req_throughput_in', 'http_error_rate_in',\n               'inbound_conns', 'outbound_conns']]\n\n\ndef service_let_graph(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests on services\n        in the current cluster. Similar to 'service_let_summary' but also breaks down\n        by pod in addition to service.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n    df = df.groupby(['service', 'remote_addr', 'pod', 'trace_role']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        latency_quantiles=('latency', px.quantiles),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df = add_time_window_column(df, start_time)\n    df.request_throughput = df.http_req_count_in / df.window\n    df.inbound_throughput = df.inbound_bytes_total / df.window\n    df.outbound_throughput = df.outbound_bytes_total / df.window\n    df.error_rate = px.Percent(df.http_error_count_in / df.http_req_count_in)\n\n    df = df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                     'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('http_req_count_in', px.sum)\n    )\n\n    return df\n    \ndef graphnode_sources(start_time: int):\n    df = service_let_graph(start_time)\n    # Use Pod name for source node id and title. If pod name is not available,\n    # use service name or IP address.\n    df.source_svc_ip = px.select(df.requestor_service != '', df.requestor_service, df.requestor_ip)\n    df.id = px.select(df.requestor_pod != '', df.requestor_pod, df.source_svc_ip)\n    df.title = df.id\n    df.arc__success = 0.1\n    df.arc__failure = 0.9\n    df = df.groupby(['id', 'title']).agg()\n    \n    return df\n\n\ndef graphnode_targets(start_time: int):\n    df = service_let_graph(start_time)\n    # Use Pod name for target node id and title. If pod name is not available,\n    # use service name or IP address.\n    df.target_svc_ip = px.select(df.responder_service != '', df.responder_service, df.responder_ip)\n    df.id = px.select(df.responder_pod != '', df.responder_pod, df.target_svc_ip)\n    df.title = df.id\n    df = df.groupby(['id', 'title']).agg()\n    \n    return df\n\n\ndef nodes(start_time: int):\n    node_sources = graphnode_sources(start_time)\n    node_targets = graphnode_targets(start_time)\n    df = node_sources.append(node_targets)\n    return df\n\n\ndef edges(start_time: int):\n    df = service_let_graph(start_time)\n    df.source_svc_ip = px.select(df.requestor_service != '', df.requestor_service, df.requestor_ip)\n    df.source = px.select(df.requestor_pod != '', df.requestor_pod, df.source_svc_ip)\n    df.target_svc_ip = px.select(df.responder_service != '', df.responder_service, df.responder_ip)\n    df.target = px.select(df.responder_pod != '', df.responder_pod, df.target_svc_ip)\n    df.id = df.source + '-' + df.target\n    df.mainStat = df.error_rate * 100\n    df.secondaryStat = df.latency_p90 / ns_per_ms\n    return df[['id', 'source', 'target', 'mainStat', 'secondaryStat']]\n\nstart_time = __time_from\n\nnodes_table = nodes(start_time)\nedges_table = edges(start_time)\npx.display(nodes_table, \"nodes\")\npx.display(edges_table, \"edges\")"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Service Map",
          "type": "nodeGraph"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "node"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 402
                  },
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/tcpoz_jnz/px-node?orgId=1&${pixieCluster:queryparam}&var-node=${__data.fields.node}&var-groupby=node"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "cpu_usage"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 129
                  },
                  {
                    "id": "unit",
                    "value": "percentunit"
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 9,
            "x": 0,
            "y": 14
          },
          "id": 4,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "import px \n\n# $pixieCluster - work around for grafana to update panel on variable change\n\ndef process_stats_by_entity(start_time: int, entity: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) per node or pod.\n    Args:\n    @start_time Starting time of the data to examine.\n    @entity: Either pod or node_name.\n    '''\n    # Window size to use on time_ column for bucketing.\n    ns_per_s = 1000 * 1000 * 1000\n    window_ns = px.DurationNanos(10 * ns_per_s)\n\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df[entity] = df.ctx[entity]\n    df.timestamp = px.bin(df.time_, window_ns)\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby([entity, 'upid', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.read_bytes = df.read_bytes_max - df.read_bytes_min\n    df.write_bytes = df.write_bytes_max - df.write_bytes_min\n    df.rchar_bytes = df.rchar_bytes_max - df.rchar_bytes_min\n    df.wchar_bytes = df.wchar_bytes_max - df.wchar_bytes_min\n    # Sum by UPID.\n    df = df.groupby([entity, 'timestamp']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        read_bytes=('read_bytes', px.sum),\n        write_bytes=('write_bytes', px.sum),\n        rchar_bytes=('rchar_bytes', px.sum),\n        wchar_bytes=('wchar_bytes', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n    df.actual_disk_read_throughput = df.read_bytes / window_ns\n    df.actual_disk_write_throughput = df.write_bytes / window_ns\n    df.total_disk_read_throughput = df.rchar_bytes / window_ns\n    df.total_disk_write_throughput = df.wchar_bytes / window_ns\n    # Now take the mean value over the various timestamps.\n    df = df.groupby(entity).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.mean),\n        cpu_utime_ns=('cpu_utime_ns', px.mean),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.mean),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.mean),\n        total_disk_read_throughput=('total_disk_read_throughput', px.mean),\n        total_disk_write_throughput=('total_disk_write_throughput', px.mean),\n        avg_rss=('rss', px.mean),\n        avg_vsize=('vsize', px.mean),\n    )\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns'])\n\ndef nodes_for_cluster(start_time: int):\n    ''' Gets a list of nodes in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.node = df.ctx['node_name']\n    df.pod = df.ctx['pod_name']\n    agg = df.groupby(['node', 'pod']).agg()\n    nodes = agg.groupby('node').agg(pod_count=('pod', px.count))\n    process_stats = process_stats_by_entity(start_time, 'node')\n    output = process_stats.merge(nodes, how='inner', left_on='node', right_on='node',\n                                 suffixes=['', '_x'])\n                                 \n    return output[['node', 'cpu_usage', 'pod_count']]\n\noutput = nodes_for_cluster(__time_from)\noutput = output[['node', 'cpu_usage', 'pod_count']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Nodes",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "namespace"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 188
                  },
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/F6XZR_j7k/px-namespace?orgId=1&${pixieCluster:queryparam}&var-namespace=${__data.fields.namespace}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "avg_vsize"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "decmbytes"
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "avg_rss"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "decmbytes"
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 15,
            "x": 9,
            "y": 14
          },
          "id": 6,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "avg_vsize_mb"
              }
            ]
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Cluster Overview\n\nThis view lists the namespaces and the nodes that are available on the current cluster.\n\n'''\nimport px\n\n\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\n# Hack to get the time window for the script.\n# TODO(philkuz): Replace this with a built-in.\ndef get_time_window(start_time: int):\n    ''' Converts the start_time string into a table with a single column and single row.\n    The approach is hacky, and will round to roughly 1 second.\n    '''\n    df = px.DataFrame('process_stats', start_time=start_time)\n\n    df = df.agg(\n        time_min=('time_', px.min),\n        time_max=('time_', px.max),\n    )\n\n    df.window = px.DurationNanos(df.time_max - df.time_min)\n    df = df[['window']]\n\n    return df\n\n\ndef add_time_window_column(df, start_time):\n    tw = get_time_window(start_time)\n    df = df.merge(tw, how='inner', left_on=[], right_on=[])\n    return df\n\n\ndef process_stats_by_entity(start_time: int, entity: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) per node or pod.\n    Args:\n    @start_time Starting time of the data to examine.\n    @entity: Either pod or node_name.\n    '''\n    # Window size to use on time_ column for bucketing.\n    ns_per_s = 1000 * 1000 * 1000\n    window_ns = px.DurationNanos(10 * ns_per_s)\n\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df[entity] = df.ctx[entity]\n    df.timestamp = px.bin(df.time_, window_ns)\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby([entity, 'upid', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.read_bytes = df.read_bytes_max - df.read_bytes_min\n    df.write_bytes = df.write_bytes_max - df.write_bytes_min\n    df.rchar_bytes = df.rchar_bytes_max - df.rchar_bytes_min\n    df.wchar_bytes = df.wchar_bytes_max - df.wchar_bytes_min\n    # Sum by UPID.\n    df = df.groupby([entity, 'timestamp']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        read_bytes=('read_bytes', px.sum),\n        write_bytes=('write_bytes', px.sum),\n        rchar_bytes=('rchar_bytes', px.sum),\n        wchar_bytes=('wchar_bytes', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n    df.actual_disk_read_throughput = df.read_bytes / window_ns\n    df.actual_disk_write_throughput = df.write_bytes / window_ns\n    df.total_disk_read_throughput = df.rchar_bytes / window_ns\n    df.total_disk_write_throughput = df.wchar_bytes / window_ns\n    # Now take the mean value over the various timestamps.\n    df = df.groupby(entity).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.mean),\n        cpu_utime_ns=('cpu_utime_ns', px.mean),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.mean),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.mean),\n        total_disk_read_throughput=('total_disk_read_throughput', px.mean),\n        total_disk_write_throughput=('total_disk_write_throughput', px.mean),\n        avg_rss=('rss', px.mean),\n        avg_vsize=('vsize', px.mean),\n    )\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns'])\n\n\ndef nodes_for_cluster(start_time: int):\n    ''' Gets a list of nodes in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.node = df.ctx['node_name']\n    df.pod = df.ctx['pod_name']\n    agg = df.groupby(['node', 'pod']).agg()\n    nodes = agg.groupby('node').agg(pod_count=('pod', px.count))\n    process_stats = process_stats_by_entity(start_time, 'node')\n    output = process_stats.merge(nodes, how='inner', left_on='node', right_on='node',\n                                 suffixes=['', '_x'])\n    return output[['node', 'cpu_usage', 'pod_count']]\n\n\ndef pods_for_cluster(start_time: int):\n    ''' A list of pods in 'namespace'.\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The name of the namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.pod = df.ctx['pod_name']\n    df.node = df.ctx['node_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'node', 'container']).agg()\n    df = df.groupby(['pod', 'node']).agg(container_count=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    process_stats = process_stats_by_entity(start_time, 'pod')\n    output = process_stats.merge(df, how='inner', left_on='pod', right_on='pod',\n                                 suffixes=['', '_x'])\n    return output[['pod', 'cpu_usage', 'total_disk_read_throughput',\n                   'total_disk_write_throughput', 'container_count',\n                   'node', 'start_time', 'status']]\n\n\ndef namespaces_for_cluster(start_time: int):\n    ''' Gets a overview of namespaces in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service_name']\n    df.pod = df.ctx['pod_name']\n    df.namespace = df.ctx['namespace']\n    agg = df.groupby(['service', 'pod', 'namespace']).agg()\n    pod_count = agg.groupby(['namespace', 'pod']).agg()\n    pod_count = pod_count.groupby('namespace').agg(pod_count=('pod', px.count))\n    svc_count = agg.groupby(['namespace', 'service']).agg()\n    svc_count = svc_count.groupby('namespace').agg(service_count=('service', px.count))\n    pod_and_svc_count = pod_count.merge(svc_count, how='inner',\n                                        left_on='namespace', right_on='namespace',\n                                        suffixes=['', '_x'])\n    process_stats = process_stats_by_entity(start_time, 'namespace')\n    output = process_stats.merge(pod_and_svc_count, how='inner', left_on='namespace',\n                                 right_on='namespace', suffixes=['', '_y'])\n    return output[['namespace', 'pod_count', 'service_count', 'avg_vsize', 'avg_rss']]\n\n\ndef services_for_cluster(start_time: int):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = service_let_summary(start_time)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef http_stats(start_time: int):\n    ''' Get a dataframe of HTTP events.\n    Certain traffic (like health checks) are auto removed, and some standard fields are added.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n\n    # Add K8s metadata.\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n\n    # Filter out non-k8s entities.\n    df = df[df.pod != '']\n\n    # Additional HTTP fields, pre-computed for convenience.\n    df.failure = df.resp_status >= 400\n\n    # Remove health checks, and anything with no remote address.\n    health_check_req = ((df.req_path == '/healthz' or df.req_path == '/readyz') or df.req_path == '/livez')\n    filter_out_conds = (health_check_req and filter_health_checks) or (df['remote_addr'] == '-')\n    df = df[not filter_out_conds]\n\n    return df\n\n\ndef http_stats_by_service(start_time: int):\n    ''' Get a data frame of HTTP stats per service. The HTTP stats are for inbound traffic,\n    and includes HTTP request count, error count and latency quantiles.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n\n    # Compute HTTP metrics.\n    df = df.groupby(['service']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        http_latency_in=('latency', px.quantiles)\n    )\n\n    return df\n\n\ndef conn_stats(start_time: int):\n    ''' Get a dataframe of connection stats.\n    For each client-server pair, the resulting data frame has the bytes sent and received.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='conn_stats', start_time=start_time)\n\n    df.pod = df.ctx['pod']\n    df.service = df.ctx['service']\n\n    df = df[df.service != '']\n\n    # Find min/max bytes transferred over the selected time window per pod.\n    df = df.groupby(['upid', 'remote_addr', 'remote_port', 'pod', 'service', 'trace_role']).agg(\n        bytes_recv_min=('bytes_recv', px.min),\n        bytes_recv_max=('bytes_recv', px.max),\n        bytes_sent_min=('bytes_sent', px.min),\n        bytes_sent_max=('bytes_sent', px.max),\n    )\n\n    # Calculate bytes transferred over the time window\n    df.bytes_sent = df.bytes_sent_max - df.bytes_sent_min\n    df.bytes_recv = df.bytes_recv_max - df.bytes_recv_min\n    df = df.drop(['bytes_recv_min', 'bytes_recv_max', 'bytes_sent_min', 'bytes_sent_max'])\n\n    return df\n\n\ndef conn_stats_by_service(start_time: int):\n    ''' Get a dataframe of connection stats aggregated by service.\n    For each service, the resulting data frame contains rx/tx stats for server-side and client-side connections.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = conn_stats(start_time)\n\n    # Group by service and trace role.\n    # Do this after computing bytes sent/received by conn_stats key ({upid, remote_addr, remote_port}).\n    # Keeping trace_role allows us to see which traffic was part of server duties vs client duties.\n    df = df.groupby(['service', 'trace_role']).agg(\n        bytes_recv=('bytes_recv', px.sum),\n        bytes_sent=('bytes_sent', px.sum),\n    )\n\n    # Get RX/TX stats for the server side connections.\n    server_df = df[df.trace_role == 2]\n    server_df.rx_server = server_df.bytes_recv\n    server_df.tx_server = server_df.bytes_sent\n    server_df = server_df[['service', 'rx_server', 'tx_server']]\n\n    # Get RX/TX stats for the client side connections.\n    client_df = df[df.trace_role == 1]\n    client_df.rx_client = client_df.bytes_recv\n    client_df.tx_client = client_df.bytes_sent\n    client_df = client_df[['service', 'rx_client', 'tx_client']]\n\n    # Create a dataframe that contains both server-side and client-side RX/TX stats.\n    df = server_df.merge(client_df,\n                         how='left',\n                         left_on='service',\n                         right_on='service',\n                         suffixes=['', '_x'])\n    df = df['service', 'rx_server', 'tx_server', 'rx_client', 'tx_client']\n\n    return df\n\n\ndef service_let_summary(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests\n        on services in the current cluster..\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    conn_stats_df = conn_stats_by_service(start_time)\n    http_stats_df = http_stats_by_service(start_time)\n\n    # Merge conn_stats_df and http_stats_df.\n    df = conn_stats_df.merge(http_stats_df,\n                             how='left',\n                             left_on='service',\n                             right_on='service',\n                             suffixes=['', '_x'])\n\n    # Compute time window for the query and add it as a column.\n    df = add_time_window_column(df, start_time)\n\n    # Compute throughput values.\n    df.http_req_throughput_in = df.http_req_count_in / df.window\n    df.http_error_rate_in = px.Percent(\n        px.select(df.http_req_count_in != 0, df.http_error_count_in / df.http_req_count_in, 0.0))\n    df.inbound_conns = (df.rx_server + df.tx_server) / df.window\n    df.outbound_conns = (df.tx_client + df.rx_client) / df.window\n\n    return df[['service', 'http_latency_in', 'http_req_throughput_in', 'http_error_rate_in',\n               'inbound_conns', 'outbound_conns']]\n\n\ndef service_let_graph(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests on services\n        in the current cluster. Similar to 'service_let_summary' but also breaks down\n        by pod in addition to service.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n    df = df.groupby(['service', 'remote_addr', 'pod', 'trace_role']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        latency_quantiles=('latency', px.quantiles),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df = add_time_window_column(df, start_time)\n    df.request_throughput = df.http_req_count_in / df.window\n    df.inbound_throughput = df.inbound_bytes_total / df.window\n    df.outbound_throughput = df.outbound_bytes_total / df.window\n    df.error_rate = px.Percent(df.http_error_count_in / df.http_req_count_in)\n\n    df = df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                     'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('http_req_count_in', px.sum)\n    )\n\n    return df\n\noutput = namespaces_for_cluster(__time_from)\noutput.avg_vsize = output.avg_vsize / px.pow(2,20)\noutput.avg_rss = output.avg_rss / px.pow(2,20)\noutput = output[['namespace', 'pod_count', 'service_count', 'avg_vsize', 'avg_rss']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Namespaces",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "decimals": 1,
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "service"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 296
                  },
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/qhHtFyCnk/px-service?orgId=1&${pixieCluster:queryparam}&var-pixieService=${__data.fields.service}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "http_latency_in_p99"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 271
                  },
                  {
                    "id": "unit",
                    "value": "ms"
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green"
                        },
                        {
                          "color": "light-orange",
                          "value": 150
                        },
                        {
                          "color": "red",
                          "value": 300
                        }
                      ]
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "http_req_throughput_in"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "/s"
                  },
                  {
                    "id": "custom.width",
                    "value": 299
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "http_error_rate_in"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "percentunit"
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "inbound_conns"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "KBs"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "outbound_conns"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "KBs"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod_count"
                },
                "properties": [
                  {
                    "id": "decimals",
                    "value": 0
                  },
                  {
                    "id": "custom.width",
                    "value": 264
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 24,
            "x": 0,
            "y": 23
          },
          "id": 8,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "http_req_throughput_in"
              }
            ]
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Cluster Overview\n\nThis view lists the namespaces and the nodes that are available on the current cluster.\n\n'''\nimport px\n\n\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\n# Hack to get the time window for the script.\n# TODO(philkuz): Replace this with a built-in.\ndef get_time_window(start_time: int):\n    ''' Converts the start_time string into a table with a single column and single row.\n    The approach is hacky, and will round to roughly 1 second.\n    '''\n    df = px.DataFrame('process_stats', start_time=start_time)\n\n    df = df.agg(\n        time_min=('time_', px.min),\n        time_max=('time_', px.max),\n    )\n\n    df.window = px.DurationNanos(df.time_max - df.time_min)\n    df = df[['window']]\n\n    return df\n\n\ndef add_time_window_column(df, start_time):\n    tw = get_time_window(start_time)\n    df = df.merge(tw, how='inner', left_on=[], right_on=[])\n    return df\n\n\ndef process_stats_by_entity(start_time: int, entity: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) per node or pod.\n    Args:\n    @start_time Starting time of the data to examine.\n    @entity: Either pod or node_name.\n    '''\n    # Window size to use on time_ column for bucketing.\n    ns_per_s = 1000 * 1000 * 1000\n    window_ns = px.DurationNanos(10 * ns_per_s)\n\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df[entity] = df.ctx[entity]\n    df.timestamp = px.bin(df.time_, window_ns)\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby([entity, 'upid', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.read_bytes = df.read_bytes_max - df.read_bytes_min\n    df.write_bytes = df.write_bytes_max - df.write_bytes_min\n    df.rchar_bytes = df.rchar_bytes_max - df.rchar_bytes_min\n    df.wchar_bytes = df.wchar_bytes_max - df.wchar_bytes_min\n    # Sum by UPID.\n    df = df.groupby([entity, 'timestamp']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        read_bytes=('read_bytes', px.sum),\n        write_bytes=('write_bytes', px.sum),\n        rchar_bytes=('rchar_bytes', px.sum),\n        wchar_bytes=('wchar_bytes', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n    df.actual_disk_read_throughput = df.read_bytes / window_ns\n    df.actual_disk_write_throughput = df.write_bytes / window_ns\n    df.total_disk_read_throughput = df.rchar_bytes / window_ns\n    df.total_disk_write_throughput = df.wchar_bytes / window_ns\n    # Now take the mean value over the various timestamps.\n    df = df.groupby(entity).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.mean),\n        cpu_utime_ns=('cpu_utime_ns', px.mean),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.mean),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.mean),\n        total_disk_read_throughput=('total_disk_read_throughput', px.mean),\n        total_disk_write_throughput=('total_disk_write_throughput', px.mean),\n        avg_rss=('rss', px.mean),\n        avg_vsize=('vsize', px.mean),\n    )\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns'])\n\n\ndef nodes_for_cluster(start_time: int):\n    ''' Gets a list of nodes in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.node = df.ctx['node_name']\n    df.pod = df.ctx['pod_name']\n    agg = df.groupby(['node', 'pod']).agg()\n    nodes = agg.groupby('node').agg(pod_count=('pod', px.count))\n    process_stats = process_stats_by_entity(start_time, 'node')\n    output = process_stats.merge(nodes, how='inner', left_on='node', right_on='node',\n                                 suffixes=['', '_x'])\n    return output[['node', 'cpu_usage', 'pod_count']]\n\n\ndef pods_for_cluster(start_time: int):\n    ''' A list of pods in 'namespace'.\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The name of the namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.pod = df.ctx['pod_name']\n    df.node = df.ctx['node_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'node', 'container']).agg()\n    df = df.groupby(['pod', 'node']).agg(container_count=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    process_stats = process_stats_by_entity(start_time, 'pod')\n    output = process_stats.merge(df, how='inner', left_on='pod', right_on='pod',\n                                 suffixes=['', '_x'])\n    return output[['pod', 'cpu_usage', 'total_disk_read_throughput',\n                   'total_disk_write_throughput', 'container_count',\n                   'node', 'start_time', 'status']]\n\n\ndef namespaces_for_cluster(start_time: int):\n    ''' Gets a overview of namespaces in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service_name']\n    df.pod = df.ctx['pod_name']\n    df.namespace = df.ctx['namespace']\n    agg = df.groupby(['service', 'pod', 'namespace']).agg()\n    pod_count = agg.groupby(['namespace', 'pod']).agg()\n    pod_count = pod_count.groupby('namespace').agg(pod_count=('pod', px.count))\n    svc_count = agg.groupby(['namespace', 'service']).agg()\n    svc_count = svc_count.groupby('namespace').agg(service_count=('service', px.count))\n    pod_and_svc_count = pod_count.merge(svc_count, how='inner',\n                                        left_on='namespace', right_on='namespace',\n                                        suffixes=['', '_x'])\n    process_stats = process_stats_by_entity(start_time, 'namespace')\n    output = process_stats.merge(pod_and_svc_count, how='inner', left_on='namespace',\n                                 right_on='namespace', suffixes=['', '_y'])\n    return output[['namespace', 'pod_count', 'service_count', 'avg_vsize', 'avg_rss']]\n\n\ndef services_for_cluster(start_time: int):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = service_let_summary(start_time)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef http_stats(start_time: int):\n    ''' Get a dataframe of HTTP events.\n    Certain traffic (like health checks) are auto removed, and some standard fields are added.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n\n    # Add K8s metadata.\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n\n    # Filter out non-k8s entities.\n    df = df[df.pod != '']\n\n    # Additional HTTP fields, pre-computed for convenience.\n    df.failure = df.resp_status >= 400\n\n    # Remove health checks, and anything with no remote address.\n    health_check_req = ((df.req_path == '/healthz' or df.req_path == '/readyz') or df.req_path == '/livez')\n    filter_out_conds = (health_check_req and filter_health_checks) or (df['remote_addr'] == '-')\n    df = df[not filter_out_conds]\n\n    return df\n\n\ndef http_stats_by_service(start_time: int):\n    ''' Get a data frame of HTTP stats per service. The HTTP stats are for inbound traffic,\n    and includes HTTP request count, error count and latency quantiles.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n\n    # Compute HTTP metrics.\n    df = df.groupby(['service']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        http_latency_in=('latency', px.quantiles)\n    )\n\n    return df\n\n\ndef conn_stats(start_time: int):\n    ''' Get a dataframe of connection stats.\n    For each client-server pair, the resulting data frame has the bytes sent and received.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='conn_stats', start_time=start_time)\n\n    df.pod = df.ctx['pod']\n    df.service = df.ctx['service']\n\n    df = df[df.service != '']\n\n    # Find min/max bytes transferred over the selected time window per pod.\n    df = df.groupby(['upid', 'remote_addr', 'remote_port', 'pod', 'service', 'trace_role']).agg(\n        bytes_recv_min=('bytes_recv', px.min),\n        bytes_recv_max=('bytes_recv', px.max),\n        bytes_sent_min=('bytes_sent', px.min),\n        bytes_sent_max=('bytes_sent', px.max),\n    )\n\n    # Calculate bytes transferred over the time window\n    df.bytes_sent = df.bytes_sent_max - df.bytes_sent_min\n    df.bytes_recv = df.bytes_recv_max - df.bytes_recv_min\n    df = df.drop(['bytes_recv_min', 'bytes_recv_max', 'bytes_sent_min', 'bytes_sent_max'])\n\n    return df\n\n\ndef conn_stats_by_service(start_time: int):\n    ''' Get a dataframe of connection stats aggregated by service.\n    For each service, the resulting data frame contains rx/tx stats for server-side and client-side connections.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = conn_stats(start_time)\n\n    # Group by service and trace role.\n    # Do this after computing bytes sent/received by conn_stats key ({upid, remote_addr, remote_port}).\n    # Keeping trace_role allows us to see which traffic was part of server duties vs client duties.\n    df = df.groupby(['service', 'trace_role']).agg(\n        bytes_recv=('bytes_recv', px.sum),\n        bytes_sent=('bytes_sent', px.sum),\n    )\n\n    # Get RX/TX stats for the server side connections.\n    server_df = df[df.trace_role == 2]\n    server_df.rx_server = server_df.bytes_recv\n    server_df.tx_server = server_df.bytes_sent\n    server_df = server_df[['service', 'rx_server', 'tx_server']]\n\n    # Get RX/TX stats for the client side connections.\n    client_df = df[df.trace_role == 1]\n    client_df.rx_client = client_df.bytes_recv\n    client_df.tx_client = client_df.bytes_sent\n    client_df = client_df[['service', 'rx_client', 'tx_client']]\n\n    # Create a dataframe that contains both server-side and client-side RX/TX stats.\n    df = server_df.merge(client_df,\n                         how='left',\n                         left_on='service',\n                         right_on='service',\n                         suffixes=['', '_x'])\n    df = df['service', 'rx_server', 'tx_server', 'rx_client', 'tx_client']\n\n    return df\n\n\ndef service_let_summary(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests\n        on services in the current cluster..\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    conn_stats_df = conn_stats_by_service(start_time)\n    http_stats_df = http_stats_by_service(start_time)\n\n    # Merge conn_stats_df and http_stats_df.\n    df = conn_stats_df.merge(http_stats_df,\n                             how='left',\n                             left_on='service',\n                             right_on='service',\n                             suffixes=['', '_x'])\n\n    # Compute time window for the query and add it as a column.\n    df = add_time_window_column(df, start_time)\n\n    # Compute throughput values.\n    df.http_req_throughput_in = df.http_req_count_in / df.window\n    df.http_error_rate_in = px.Percent(\n        px.select(df.http_req_count_in != 0, df.http_error_count_in / df.http_req_count_in, 0.0))\n    df.inbound_conns = (df.rx_server + df.tx_server) / df.window\n    df.outbound_conns = (df.tx_client + df.rx_client) / df.window\n\n    return df[['service', 'http_latency_in', 'http_req_throughput_in', 'http_error_rate_in',\n               'inbound_conns', 'outbound_conns']]\n\n\ndef service_let_graph(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests on services\n        in the current cluster. Similar to 'service_let_summary' but also breaks down\n        by pod in addition to service.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n    df = df.groupby(['service', 'remote_addr', 'pod', 'trace_role']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        latency_quantiles=('latency', px.quantiles),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df = add_time_window_column(df, start_time)\n    df.request_throughput = df.http_req_count_in / df.window\n    df.inbound_throughput = df.inbound_bytes_total / df.window\n    df.outbound_throughput = df.outbound_bytes_total / df.window\n    df.error_rate = px.Percent(df.http_error_count_in / df.http_req_count_in)\n\n    df = df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                     'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('http_req_count_in', px.sum)\n    )\n\n    return df\n\noutput = services_for_cluster(__time_from)\noutput.http_latency_in_p99 = px.pluck_float64(output.http_latency_in, 'p99') / px.pow(10,6)\noutput.http_req_throughput_in = output.http_req_throughput_in * px.pow(10,9)\noutput.inbound_conns = output.inbound_conns * px.pow(10,9) / px.pow(2,10)\noutput.outbound_conns = output.outbound_conns * px.pow(10,9) / px.pow(2,10)\noutput = output[['service', 'pod_count', 'http_latency_in_p99', 'http_req_throughput_in', 'http_error_rate_in', 'inbound_conns', 'outbound_conns']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Services",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "decimals": 1,
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 378
                  },
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.pod}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "ready"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 66
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "phase"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "custom.width",
                    "value": 73
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "cpu_usage"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 162
                  },
                  {
                    "id": "unit",
                    "value": "percentunit"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "total_disk_read_throughput"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 274
                  },
                  {
                    "id": "unit",
                    "value": "KBs"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "container_count"
                },
                "properties": [
                  {
                    "id": "decimals"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "total_disk_write_throughput"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "KBs"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "node"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/tcpoz_jnz/px-node?orgId=1&${pixieCluster:queryparam}&var-node=${__data.fields.node}&var-groupby=node"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 24,
            "x": 0,
            "y": 32
          },
          "id": 10,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Cluster Overview\n\nThis view lists the namespaces and the nodes that are available on the current cluster.\n\n'''\nimport px\n\n\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\n# Hack to get the time window for the script.\n# TODO(philkuz): Replace this with a built-in.\ndef get_time_window(start_time: int):\n    ''' Converts the start_time string into a table with a single column and single row.\n    The approach is hacky, and will round to roughly 1 second.\n    '''\n    df = px.DataFrame('process_stats', start_time=start_time)\n\n    df = df.agg(\n        time_min=('time_', px.min),\n        time_max=('time_', px.max),\n    )\n\n    df.window = px.DurationNanos(df.time_max - df.time_min)\n    df = df[['window']]\n\n    return df\n\n\ndef add_time_window_column(df, start_time):\n    tw = get_time_window(start_time)\n    df = df.merge(tw, how='inner', left_on=[], right_on=[])\n    return df\n\n\ndef process_stats_by_entity(start_time: int, entity: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) per node or pod.\n    Args:\n    @start_time Starting time of the data to examine.\n    @entity: Either pod or node_name.\n    '''\n    # Window size to use on time_ column for bucketing.\n    ns_per_s = 1000 * 1000 * 1000\n    window_ns = px.DurationNanos(10 * ns_per_s)\n\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df[entity] = df.ctx[entity]\n    df.timestamp = px.bin(df.time_, window_ns)\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby([entity, 'upid', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.read_bytes = df.read_bytes_max - df.read_bytes_min\n    df.write_bytes = df.write_bytes_max - df.write_bytes_min\n    df.rchar_bytes = df.rchar_bytes_max - df.rchar_bytes_min\n    df.wchar_bytes = df.wchar_bytes_max - df.wchar_bytes_min\n    # Sum by UPID.\n    df = df.groupby([entity, 'timestamp']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        read_bytes=('read_bytes', px.sum),\n        write_bytes=('write_bytes', px.sum),\n        rchar_bytes=('rchar_bytes', px.sum),\n        wchar_bytes=('wchar_bytes', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n    df.actual_disk_read_throughput = df.read_bytes / window_ns\n    df.actual_disk_write_throughput = df.write_bytes / window_ns\n    df.total_disk_read_throughput = df.rchar_bytes / window_ns\n    df.total_disk_write_throughput = df.wchar_bytes / window_ns\n    # Now take the mean value over the various timestamps.\n    df = df.groupby(entity).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.mean),\n        cpu_utime_ns=('cpu_utime_ns', px.mean),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.mean),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.mean),\n        total_disk_read_throughput=('total_disk_read_throughput', px.mean),\n        total_disk_write_throughput=('total_disk_write_throughput', px.mean),\n        avg_rss=('rss', px.mean),\n        avg_vsize=('vsize', px.mean),\n    )\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns'])\n\n\ndef nodes_for_cluster(start_time: int):\n    ''' Gets a list of nodes in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.node = df.ctx['node_name']\n    df.pod = df.ctx['pod_name']\n    agg = df.groupby(['node', 'pod']).agg()\n    nodes = agg.groupby('node').agg(pod_count=('pod', px.count))\n    process_stats = process_stats_by_entity(start_time, 'node')\n    output = process_stats.merge(nodes, how='inner', left_on='node', right_on='node',\n                                 suffixes=['', '_x'])\n    return output[['node', 'cpu_usage', 'pod_count']]\n\n\ndef pods_for_cluster(start_time: int):\n    ''' A list of pods in 'namespace'.\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The name of the namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.pod = df.ctx['pod_name']\n    df.node = df.ctx['node_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'node', 'container']).agg()\n    df = df.groupby(['pod', 'node']).agg(container_count=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    process_stats = process_stats_by_entity(start_time, 'pod')\n    output = process_stats.merge(df, how='inner', left_on='pod', right_on='pod',\n                                 suffixes=['', '_x'])\n    return output[['pod', 'cpu_usage', 'total_disk_read_throughput',\n                   'total_disk_write_throughput', 'container_count',\n                   'node', 'start_time', 'status']]\n\n\ndef namespaces_for_cluster(start_time: int):\n    ''' Gets a overview of namespaces in the current cluster since 'start_time'.\n    Args:\n    @start_time Start time of the data to examine.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service_name']\n    df.pod = df.ctx['pod_name']\n    df.namespace = df.ctx['namespace']\n    agg = df.groupby(['service', 'pod', 'namespace']).agg()\n    pod_count = agg.groupby(['namespace', 'pod']).agg()\n    pod_count = pod_count.groupby('namespace').agg(pod_count=('pod', px.count))\n    svc_count = agg.groupby(['namespace', 'service']).agg()\n    svc_count = svc_count.groupby('namespace').agg(service_count=('service', px.count))\n    pod_and_svc_count = pod_count.merge(svc_count, how='inner',\n                                        left_on='namespace', right_on='namespace',\n                                        suffixes=['', '_x'])\n    process_stats = process_stats_by_entity(start_time, 'namespace')\n    output = process_stats.merge(pod_and_svc_count, how='inner', left_on='namespace',\n                                 right_on='namespace', suffixes=['', '_y'])\n    return output[['namespace', 'pod_count', 'service_count', 'avg_vsize', 'avg_rss']]\n\n\ndef services_for_cluster(start_time: int):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = service_let_summary(start_time)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef http_stats(start_time: int):\n    ''' Get a dataframe of HTTP events.\n    Certain traffic (like health checks) are auto removed, and some standard fields are added.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n\n    # Add K8s metadata.\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n\n    # Filter out non-k8s entities.\n    df = df[df.pod != '']\n\n    # Additional HTTP fields, pre-computed for convenience.\n    df.failure = df.resp_status >= 400\n\n    # Remove health checks, and anything with no remote address.\n    health_check_req = ((df.req_path == '/healthz' or df.req_path == '/readyz') or df.req_path == '/livez')\n    filter_out_conds = (health_check_req and filter_health_checks) or (df['remote_addr'] == '-')\n    df = df[not filter_out_conds]\n\n    return df\n\n\ndef http_stats_by_service(start_time: int):\n    ''' Get a data frame of HTTP stats per service. The HTTP stats are for inbound traffic,\n    and includes HTTP request count, error count and latency quantiles.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n\n    # Compute HTTP metrics.\n    df = df.groupby(['service']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        http_latency_in=('latency', px.quantiles)\n    )\n\n    return df\n\n\ndef conn_stats(start_time: int):\n    ''' Get a dataframe of connection stats.\n    For each client-server pair, the resulting data frame has the bytes sent and received.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='conn_stats', start_time=start_time)\n\n    df.pod = df.ctx['pod']\n    df.service = df.ctx['service']\n\n    df = df[df.service != '']\n\n    # Find min/max bytes transferred over the selected time window per pod.\n    df = df.groupby(['upid', 'remote_addr', 'remote_port', 'pod', 'service', 'trace_role']).agg(\n        bytes_recv_min=('bytes_recv', px.min),\n        bytes_recv_max=('bytes_recv', px.max),\n        bytes_sent_min=('bytes_sent', px.min),\n        bytes_sent_max=('bytes_sent', px.max),\n    )\n\n    # Calculate bytes transferred over the time window\n    df.bytes_sent = df.bytes_sent_max - df.bytes_sent_min\n    df.bytes_recv = df.bytes_recv_max - df.bytes_recv_min\n    df = df.drop(['bytes_recv_min', 'bytes_recv_max', 'bytes_sent_min', 'bytes_sent_max'])\n\n    return df\n\n\ndef conn_stats_by_service(start_time: int):\n    ''' Get a dataframe of connection stats aggregated by service.\n    For each service, the resulting data frame contains rx/tx stats for server-side and client-side connections.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = conn_stats(start_time)\n\n    # Group by service and trace role.\n    # Do this after computing bytes sent/received by conn_stats key ({upid, remote_addr, remote_port}).\n    # Keeping trace_role allows us to see which traffic was part of server duties vs client duties.\n    df = df.groupby(['service', 'trace_role']).agg(\n        bytes_recv=('bytes_recv', px.sum),\n        bytes_sent=('bytes_sent', px.sum),\n    )\n\n    # Get RX/TX stats for the server side connections.\n    server_df = df[df.trace_role == 2]\n    server_df.rx_server = server_df.bytes_recv\n    server_df.tx_server = server_df.bytes_sent\n    server_df = server_df[['service', 'rx_server', 'tx_server']]\n\n    # Get RX/TX stats for the client side connections.\n    client_df = df[df.trace_role == 1]\n    client_df.rx_client = client_df.bytes_recv\n    client_df.tx_client = client_df.bytes_sent\n    client_df = client_df[['service', 'rx_client', 'tx_client']]\n\n    # Create a dataframe that contains both server-side and client-side RX/TX stats.\n    df = server_df.merge(client_df,\n                         how='left',\n                         left_on='service',\n                         right_on='service',\n                         suffixes=['', '_x'])\n    df = df['service', 'rx_server', 'tx_server', 'rx_client', 'tx_client']\n\n    return df\n\n\ndef service_let_summary(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests\n        on services in the current cluster..\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    conn_stats_df = conn_stats_by_service(start_time)\n    http_stats_df = http_stats_by_service(start_time)\n\n    # Merge conn_stats_df and http_stats_df.\n    df = conn_stats_df.merge(http_stats_df,\n                             how='left',\n                             left_on='service',\n                             right_on='service',\n                             suffixes=['', '_x'])\n\n    # Compute time window for the query and add it as a column.\n    df = add_time_window_column(df, start_time)\n\n    # Compute throughput values.\n    df.http_req_throughput_in = df.http_req_count_in / df.window\n    df.http_error_rate_in = px.Percent(\n        px.select(df.http_req_count_in != 0, df.http_error_count_in / df.http_req_count_in, 0.0))\n    df.inbound_conns = (df.rx_server + df.tx_server) / df.window\n    df.outbound_conns = (df.tx_client + df.rx_client) / df.window\n\n    return df[['service', 'http_latency_in', 'http_req_throughput_in', 'http_error_rate_in',\n               'inbound_conns', 'outbound_conns']]\n\n\ndef service_let_graph(start_time: int):\n    ''' Compute a summary of traffic by requesting service, for requests on services\n        in the current cluster. Similar to 'service_let_summary' but also breaks down\n        by pod in addition to service.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = http_stats(start_time)\n    df = df.groupby(['service', 'remote_addr', 'pod', 'trace_role']).agg(\n        http_req_count_in=('latency', px.count),\n        http_error_count_in=('failure', px.sum),\n        latency_quantiles=('latency', px.quantiles),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df = add_time_window_column(df, start_time)\n    df.request_throughput = df.http_req_count_in / df.window\n    df.inbound_throughput = df.inbound_bytes_total / df.window\n    df.outbound_throughput = df.outbound_bytes_total / df.window\n    df.error_rate = px.Percent(df.http_error_count_in / df.http_req_count_in)\n\n    df = df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                     'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('http_req_count_in', px.sum)\n    )\n\n    return df\n\noutput = pods_for_cluster(__time_from)\noutput.total_disk_read_throughput =  output.total_disk_read_throughput * px.pow(10,9) / px.pow(2,10)\noutput.total_disk_write_throughput = output.total_disk_write_throughput * px.pow(10,9) / px.pow(2,10)\nphase = px.pluck(output.status, \"phase\") \nready = px.pluck(output.status, \"ready\")  \n\noutput.phase = px.pluck(output.status, \"phase\") \noutput.ready = px.pluck(output.status, \"ready\") \n\noutput = output[['pod', 'phase', 'ready', 'cpu_usage', 'total_disk_read_throughput', 'total_disk_write_throughput', 'container_count', 'node', 'start_time']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Pods",
          "type": "table"
        }
      ],
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Clusters",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieCluster",
            "options": [],
            "query": {
              "queryType": "get-clusters"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Pixie K8s Cluster Overview",
      "description": "Dashboard includes a service map of the HTTP traffic between the services in your cluster, along with the latency, error rate, and throughput per service. It also lists the nodes, namespaces and pods available in your cluster. To learn how to monitor service performance and infrastructure health using Pixie, see https://docs.px.dev/tutorials/pixie-101/service-performance/",
      "uid": "JMSOCJj7k",
      "version": 1,
      "weekStart": ""
    }
    `}}
  pixie-http-data.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "DS_PIXIE_GRAFANA DATASOURCE PLUGIN",
          "label": "Pixie Grafana Datasource Plugin",
          "description": "",
          "type": "datasource",
          "pluginId": "pixie-pixie-datasource",
          "pluginName": "Pixie Grafana Datasource Plugin"
        }
      ],
      "__requires": [
        {
          "type": "datasource",
          "id": "pixie-pixie-datasource",
          "name": "Pixie Grafana Datasource Plugin",
          "version": "0.0.9"
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1657240479716,
      "links": [],
      "panels": [
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "latency"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "ms"
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green",
                          "value": null
                        },
                        {
                          "color": "light-orange",
                          "value": 150
                        },
                        {
                          "color": "red",
                          "value": 300
                        }
                      ]
                    }
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "req_body_size"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "decbytes"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "resp_status"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green",
                          "value": null
                        },
                        {
                          "color": "red",
                          "value": 400
                        }
                      ]
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "resp_body_size"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "deckbytes"
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "source"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.source}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "destination"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.destination}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 22,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "latency"
              }
            ]
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' HTTP Data Tracer\n\nThis script traces all HTTP/HTTP2 data on the cluster.\n'''\nimport px\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\ndef http_data(start_time: int, source_filter: str, destination_filter: str, num_head: int):\n\n    df = px.DataFrame(table='http_events', start_time=start_time)\n\n    # Add context.\n    df.node = df.ctx['node']\n    df.pid = px.upid_to_pid(df.upid)\n    df = add_source_dest_columns(df)\n\n    # Filter out entities as specified by the user.\n    df = df[px.contains(df.source, source_filter)]\n    df = df[px.contains(df.destination, destination_filter)]\n\n    # Add additional filters below:\n\n    # Restrict number of results.\n    df = df.head(num_head)\n    # Avoid conversion to wide format\n    df.timestamp = df.time_\n    df = df.drop(columns=['time_'])\n    \n    df.latency = df.latency / px.pow(10,6)\n    df.resp_body_size = df.resp_body_size / px.pow(2,10) \n\n    # Order columns.\n    df = df['timestamp', 'source', 'destination', 'latency', 'major_version', 'req_path',\n            'req_method', 'req_headers', 'req_body', 'req_body_size', 'resp_status',\n            'resp_message', 'resp_headers', 'resp_body', 'resp_body_size']\n\n    return df\n\n\ndef add_source_dest_columns(df):\n    ''' Add source and destination columns for the HTTP request.\n\n    HTTP requests are traced server-side (trace_role==2), unless the server is\n    outside of the cluster in which case the request is traced client-side (trace_role==1).\n\n    When trace_role==2, the HTTP request source is the remote_addr column\n    and destination is the pod column. When trace_role==1, the HTTP request\n    source is the pod column and the destination is the remote_addr column.\n\n    Input DataFrame must contain trace_role, upid, remote_addr columns.\n    '''\n    df.pod = df.ctx['pod']\n    df.namespace = df.ctx['namespace']\n\n    # If remote_addr is a pod, get its name. If not, use IP address.\n    df.ra_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.is_ra_pod = df.ra_pod != ''\n    df.ra_name = px.select(df.is_ra_pod, df.ra_pod, df.remote_addr)\n\n    df.is_server_tracing = df.trace_role == 2\n    df.is_source_pod_type = px.select(df.is_server_tracing, df.is_ra_pod, True)\n    df.is_dest_pod_type = px.select(df.is_server_tracing, True, df.is_ra_pod)\n\n    # Set source and destination based on trace_role.\n    df.source = px.select(df.is_server_tracing, df.ra_name, df.pod)\n    df.destination = px.select(df.is_server_tracing, df.pod, df.ra_name)\n\n    # Filter out messages with empty source / destination.\n    df = df[df.source != '']\n    df = df[df.destination != '']\n\n    df = df.drop(['ra_pod', 'is_ra_pod', 'ra_name', 'is_server_tracing'])\n    return df\n\noutput = http_data($__from, '$sourceFilter', '$destinationFilter', $maxNumRecords)\n\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Table",
          "type": "table"
        }
      ],
      "refresh": 2,
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Clusters",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieCluster",
            "options": [],
            "query": {
              "queryType": "get-clusters"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          },
          {
            "current": {
              "selected": false,
              "text": "",
              "value": ""
            },
            "description": "The partial string to match the 'source' column",
            "hide": 0,
            "name": "sourceFilter",
            "options": [
              {
                "selected": true,
                "text": "",
                "value": ""
              }
            ],
            "query": "",
            "skipUrlSync": false,
            "type": "textbox"
          },
          {
            "current": {
              "selected": false,
              "text": "",
              "value": ""
            },
            "description": "The partial string to match the 'destination' column",
            "hide": 0,
            "name": "destinationFilter",
            "options": [
              {
                "selected": true,
                "text": "",
                "value": ""
              }
            ],
            "query": "",
            "skipUrlSync": false,
            "type": "textbox"
          },
          {
            "current": {
              "selected": false,
              "text": "1000",
              "value": "1000"
            },
            "hide": 0,
            "name": "maxNumRecords",
            "options": [
              {
                "selected": true,
                "text": "1000",
                "value": "1000"
              }
            ],
            "query": "1000",
            "skipUrlSync": false,
            "type": "textbox"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Pixie HTTP Traces",
      "description": "Dashboard includes a table of the most recent full-body HTTP messages in your cluster. For more info about request tracing using Pixie, see https://docs.px.dev/tutorials/pixie-101/request-tracing",
      "uid": "HDxrIyjnz",
      "version": 1,
      "weekStart": ""
    }
    `}}
  pixie-namespace.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "DS_PIXIE_GRAFANA DATASOURCE PLUGIN",
          "label": "Pixie Grafana Datasource Plugin",
          "description": "",
          "type": "datasource",
          "pluginId": "pixie-pixie-datasource",
          "pluginName": "Pixie Grafana Datasource Plugin"
        }
      ],
      "__requires": [
        {
          "type": "panel",
          "id": "nodeGraph",
          "name": "Node Graph",
          "version": ""
        },
        {
          "type": "datasource",
          "id": "pixie-pixie-datasource",
          "name": "Pixie Grafana Datasource Plugin",
          "version": "0.0.9"
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "description": "",
      "editable": true,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1657153889922,
      "links": [],
      "panels": [
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "gridPos": {
            "h": 13,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "targets": [
            {
              "datasource": {
                "type": "pixie-pixie-datasource",
                "uid": "pixie"
              },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Namespace Overview\n\nThis view gives a top-level summary of the pods and services in a given namespace,\nas well as a service map.\n\n'''\nimport px\n\n\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\nstart_time = __time_from\n\ndef pods_for_namespace(start_time: int, namespace: px.Namespace):\n    ''' Gets a list of pods running per node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @namespace: The namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['namespace'] == namespace]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby(['pod']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n    )\n\n    df.create_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef services_for_namespace(start_time: int, namespace: px.Namespace):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['namespace'] == namespace]\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = inbound_service_let_summary(start_time, namespace)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef inbound_service_let_summary(start_time: int, namespace: px.Namespace):\n    ''' Compute a summary of traffic by requesting service, for requests on services in 'namespace'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = inbound_service_let_helper(start_time, namespace)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df = df[df.service != '']\n    df.responder = df.service\n    per_ns_df = df.groupby(['timestamp', 'service']).agg(\n        http_throughput_total=('latency', px.count),\n        inbound_http_bytes_total=('req_body_size', px.sum),\n        outbound_http_bytes_total=('resp_body_size', px.sum)\n    )\n    per_ns_df.http_request_throughput = per_ns_df.http_throughput_total / window_ns\n    per_ns_df.inbound_http_throughput = per_ns_df.inbound_http_bytes_total / window_ns\n    per_ns_df.outbound_http_throughput = per_ns_df.outbound_http_bytes_total / window_ns\n    per_ns_df = per_ns_df.groupby('service').agg(\n        http_request_throughput=('http_request_throughput', px.mean),\n        inbound_http_throughput=('inbound_http_throughput', px.mean),\n        outbound_http_throughput=('outbound_http_throughput', px.mean)\n    )\n    quantiles_df = df.groupby('service').agg(\n        http_latency=('latency', px.quantiles)\n        http_error_rate=('failure', px.mean),\n    )\n    quantiles_df.http_error_rate = px.Percent(quantiles_df.http_error_rate)\n    joined = per_ns_df.merge(quantiles_df, left_on='service',\n                             right_on='service', how='inner',\n                             suffixes=['', '_x'])\n    return joined[['service', 'http_latency', 'http_request_throughput', 'http_error_rate',\n                   'inbound_http_throughput', 'outbound_http_throughput']]\n\n\ndef inbound_service_let_graph(start_time: int, namespace: px.Namespace):\n    ''' Compute a summary of traffic by requesting service, for requests on services in 'namespace'.\n        Similar to 'inbound_let_summary' but also breaks down by pod in addition to service.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = inbound_service_let_helper(start_time, namespace)\n    df = df.groupby(['timestamp', 'service', 'remote_addr', 'pod', 'trace_role']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.inbound_throughput = df.inbound_bytes_total / window_ns\n    df.outbound_throughput = df.outbound_bytes_total / window_ns\n    df.error_rate = px.Percent(df.error_rate)\n    return df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                       'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('throughput_total', px.sum)\n    )\n\n\ndef inbound_service_let_helper(start_time: int, namespace: px.Namespace):\n    ''' Compute the let as a timeseries for requests received or by services in 'namespace'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod_name']\n    df = df[df.ctx['namespace'] == namespace]\n    df = df[df.pod != '']\n    df.latency = df.latency\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n\n    \ndef graphnode_sources(start_time: int):\n    df = inbound_service_let_graph(start_time, '$namespace')\n    # Use Pod name for source node id and title. If pod name is not available,\n    # use service name or IP address.\n    df.source_svc_ip = px.select(df.requestor_service != '', df.requestor_service, df.requestor_ip)\n    df.id = px.select(df.requestor_pod != '', df.requestor_pod, df.source_svc_ip)\n    df.title = df.id\n    df.arc__success = 0.1\n    df.arc__failure = 0.9\n    df = df.groupby(['id', 'title']).agg()\n    \n    return df\n\n\ndef graphnode_targets(start_time: int):\n    df = inbound_service_let_graph(start_time, '$namespace')\n    # Use Pod name for target node id and title. If pod name is not available,\n    # use service name or IP address.\n    df.target_svc_ip = px.select(df.responder_service != '', df.responder_service, df.responder_ip)\n    df.id = px.select(df.responder_pod != '', df.responder_pod, df.target_svc_ip)\n    df.title = df.id\n    df = df.groupby(['id', 'title']).agg()\n    \n    return df\n\n\ndef nodes(start_time: int):\n    node_sources = graphnode_sources(start_time)\n    node_targets = graphnode_targets(start_time)\n    df = node_sources.append(node_targets)\n    return df\n\n\ndef edges(start_time: int):\n    df = inbound_service_let_graph(start_time, '$namespace')\n    df.source_svc_ip = px.select(df.requestor_service != '', df.requestor_service, df.requestor_ip)\n    df.source = px.select(df.requestor_pod != '', df.requestor_pod, df.source_svc_ip)\n    df.target_svc_ip = px.select(df.responder_service != '', df.responder_service, df.responder_ip)\n    df.target = px.select(df.responder_pod != '', df.responder_pod, df.target_svc_ip)\n    df.id = df.source + '-' + df.target\n    df.mainStat = df.error_rate * 100\n    df.secondaryStat = df.latency_p90 / ns_per_ms\n    return df[['id', 'source', 'target', 'mainStat', 'secondaryStat']]\n\n\nnodes_table = nodes(start_time)\nedges_table = edges(start_time)\npx.display(nodes_table, \"nodes\")\npx.display(edges_table, \"edges\")"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Service Map",
          "type": "nodeGraph"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "decimals": 1,
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "light-orange",
                    "value": 150
                  },
                  {
                    "color": "red",
                    "value": 300
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod_count"
                },
                "properties": [
                  {
                    "id": "decimals"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "http_latency_p99"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "unit",
                    "value": "ms"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "http_error_rate"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "percentunit"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "http_request_throughput"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "/s"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "inbound_http_throughput"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "KBs"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "outbound_http_throughput"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "KBs"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "service"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "targetBlank": false,
                        "title": "Service",
                        "url": "/d/qhHtFyCnk/px-service?orgId=1&${pixieCluster:queryparam}&var-pixieService=${__data.fields.service}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 13,
            "w": 24,
            "x": 0,
            "y": 13
          },
          "id": 3,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
                "type": "pixie-pixie-datasource",
                "uid": "pixie"
              },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Namespace Overview\n\nThis view gives a top-level summary of the pods and services in a given namespace,\nas well as a service map.\n\n'''\nimport px\n\n\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\nstart_time = __time_from\n\ndef pods_for_namespace(start_time: int, namespace: px.Namespace):\n    ''' Gets a list of pods running per node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @namespace: The namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['namespace'] == namespace]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby(['pod']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n    )\n\n    df.create_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef services_for_namespace(start_time: int, namespace: px.Namespace):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['namespace'] == namespace]\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = inbound_service_let_summary(start_time, namespace)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef inbound_service_let_summary(start_time: int, namespace: px.Namespace):\n    ''' Compute a summary of traffic by requesting service, for requests on services in 'namespace'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = inbound_service_let_helper(start_time, namespace)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df = df[df.service != '']\n    df.responder = df.service\n    per_ns_df = df.groupby(['timestamp', 'service']).agg(\n        http_throughput_total=('latency', px.count),\n        inbound_http_bytes_total=('req_body_size', px.sum),\n        outbound_http_bytes_total=('resp_body_size', px.sum)\n    )\n    per_ns_df.http_request_throughput = per_ns_df.http_throughput_total / window_ns\n    per_ns_df.inbound_http_throughput = per_ns_df.inbound_http_bytes_total / window_ns\n    per_ns_df.outbound_http_throughput = per_ns_df.outbound_http_bytes_total / window_ns\n    per_ns_df = per_ns_df.groupby('service').agg(\n        http_request_throughput=('http_request_throughput', px.mean),\n        inbound_http_throughput=('inbound_http_throughput', px.mean),\n        outbound_http_throughput=('outbound_http_throughput', px.mean)\n    )\n    quantiles_df = df.groupby('service').agg(\n        http_latency=('latency', px.quantiles)\n        http_error_rate=('failure', px.mean),\n    )\n    quantiles_df.http_error_rate = px.Percent(quantiles_df.http_error_rate)\n    joined = per_ns_df.merge(quantiles_df, left_on='service',\n                             right_on='service', how='inner',\n                             suffixes=['', '_x'])\n    return joined[['service', 'http_latency', 'http_request_throughput', 'http_error_rate',\n                   'inbound_http_throughput', 'outbound_http_throughput']]\n\n\ndef inbound_service_let_graph(start_time: int, namespace: px.Namespace):\n    ''' Compute a summary of traffic by requesting service, for requests on services in 'namespace'.\n        Similar to 'inbound_let_summary' but also breaks down by pod in addition to service.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = inbound_service_let_helper(start_time, namespace)\n    df = df.groupby(['timestamp', 'service', 'remote_addr', 'pod', 'trace_role']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.inbound_throughput = df.inbound_bytes_total / window_ns\n    df.outbound_throughput = df.outbound_bytes_total / window_ns\n    df.error_rate = px.Percent(df.error_rate)\n    return df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                       'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('throughput_total', px.sum)\n    )\n\n\ndef inbound_service_let_helper(start_time: int, namespace: px.Namespace):\n    ''' Compute the let as a timeseries for requests received or by services in 'namespace'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod_name']\n    df = df[df.ctx['namespace'] == namespace]\n    df = df[df.pod != '']\n    df.latency = df.latency\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n\ndf = services_for_namespace(start_time, '$namespace')\ndf.http_latency_p99 = px.pluck_float64(df.http_latency,'p99') / px.pow(10,6)\ndf.http_request_throughput = df.http_request_throughput * px.pow(10,9)\ndf.inbound_http_throughput = df.inbound_http_throughput * px.pow(10,9) / px.pow(2, 10)\ndf.outbound_http_throughput = df.outbound_http_throughput * px.pow(10,9) / px.pow(2, 10)\n\ndf = df[['service', 'pod_count', 'http_latency_p99', 'http_request_throughput', 'http_error_rate', 'inbound_http_throughput', 'outbound_http_throughput']]\npx.display(df)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Service List",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "decimals": 1,
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "light-orange",
                    "value": 150
                  },
                  {
                    "color": "red",
                    "value": 300
                  }
                ]
              },
              "unit": "decmbytes"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "phase"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 142
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "ready"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 86
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "ready"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.pod}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 15,
            "w": 24,
            "x": 0,
            "y": 26
          },
          "id": 4,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
                "type": "pixie-pixie-datasource",
                "uid": "pixie"
              },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Namespace Overview\n\nThis view gives a top-level summary of the pods and services in a given namespace,\nas well as a service map.\n\n'''\nimport px\n\n\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Whether or not to include traffic from IPs that don't resolve to a known pod/service.\ninclude_ips = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\nstart_time = __time_from\n\ndef pods_for_namespace(start_time: int, namespace: px.Namespace):\n    ''' Gets a list of pods running per node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @namespace: The namespace to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['namespace'] == namespace]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby(['pod']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n    )\n\n    df.create_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef services_for_namespace(start_time: int, namespace: px.Namespace):\n    ''' Get an overview of the services in the current cluster.\n    Args:\n    @start_time: The timestamp of data to start at.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['namespace'] == namespace]\n    df.service = df.ctx['service']\n    df = df[df.service != '']\n    df.pod = df.ctx['pod']\n    df = df.groupby(['service', 'pod']).agg()\n    df = df.groupby('service').agg(pod_count=('pod', px.count))\n    service_let = inbound_service_let_summary(start_time, namespace)\n    joined = df.merge(service_let, how='left', left_on='service', right_on='service',\n                      suffixes=['', '_x'])\n    return joined.drop('service_x')\n\n\ndef inbound_service_let_summary(start_time: int, namespace: px.Namespace):\n    ''' Compute a summary of traffic by requesting service, for requests on services in 'namespace'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = inbound_service_let_helper(start_time, namespace)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df = df[df.service != '']\n    df.responder = df.service\n    per_ns_df = df.groupby(['timestamp', 'service']).agg(\n        http_throughput_total=('latency', px.count),\n        inbound_http_bytes_total=('req_body_size', px.sum),\n        outbound_http_bytes_total=('resp_body_size', px.sum)\n    )\n    per_ns_df.http_request_throughput = per_ns_df.http_throughput_total / window_ns\n    per_ns_df.inbound_http_throughput = per_ns_df.inbound_http_bytes_total / window_ns\n    per_ns_df.outbound_http_throughput = per_ns_df.outbound_http_bytes_total / window_ns\n    per_ns_df = per_ns_df.groupby('service').agg(\n        http_request_throughput=('http_request_throughput', px.mean),\n        inbound_http_throughput=('inbound_http_throughput', px.mean),\n        outbound_http_throughput=('outbound_http_throughput', px.mean)\n    )\n    quantiles_df = df.groupby('service').agg(\n        http_latency=('latency', px.quantiles)\n        http_error_rate=('failure', px.mean),\n    )\n    quantiles_df.http_error_rate = px.Percent(quantiles_df.http_error_rate)\n    joined = per_ns_df.merge(quantiles_df, left_on='service',\n                             right_on='service', how='inner',\n                             suffixes=['', '_x'])\n    return joined[['service', 'http_latency', 'http_request_throughput', 'http_error_rate',\n                   'inbound_http_throughput', 'outbound_http_throughput']]\n\n\ndef inbound_service_let_graph(start_time: int, namespace: px.Namespace):\n    ''' Compute a summary of traffic by requesting service, for requests on services in 'namespace'.\n        Similar to 'inbound_let_summary' but also breaks down by pod in addition to service.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = inbound_service_let_helper(start_time, namespace)\n    df = df.groupby(['timestamp', 'service', 'remote_addr', 'pod', 'trace_role']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        inbound_bytes_total=('req_body_size', px.sum),\n        outbound_bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Get the traced and remote pod/service/IP information.\n    df.traced_pod = df.pod\n    df.traced_service = df.service\n    df.traced_ip = px.pod_name_to_pod_ip(df.pod)\n    df.remote_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.remote_service = px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr))\n    df.remote_ip = df.remote_addr\n    # If external IPs are excluded in the service graph, then we also exclude any\n    # traffic where we don't know the remote pod or remote service name.\n    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]\n\n    # Associate it with Client/Server roles, based on the trace role.\n    df.is_server_side_tracing = df.trace_role == 2\n    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)\n    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)\n    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)\n    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)\n    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)\n    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)\n\n    # Compute statistics about each edge of the service graph.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.inbound_throughput = df.inbound_bytes_total / window_ns\n    df.outbound_throughput = df.outbound_bytes_total / window_ns\n    df.error_rate = px.Percent(df.error_rate)\n    return df.groupby(['responder_pod', 'requestor_pod', 'responder_service',\n                       'requestor_service', 'responder_ip', 'requestor_ip']).agg(\n        latency_p50=('latency_p50', px.mean),\n        latency_p90=('latency_p90', px.mean),\n        latency_p99=('latency_p99', px.mean),\n        request_throughput=('request_throughput', px.mean),\n        error_rate=('error_rate', px.mean),\n        inbound_throughput=('inbound_throughput', px.mean),\n        outbound_throughput=('outbound_throughput', px.mean),\n        throughput_total=('throughput_total', px.sum)\n    )\n\n\ndef inbound_service_let_helper(start_time: int, namespace: px.Namespace):\n    ''' Compute the let as a timeseries for requests received or by services in 'namespace'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @namespace: The namespace to filter on.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod_name']\n    df = df[df.ctx['namespace'] == namespace]\n    df = df[df.pod != '']\n    df.latency = df.latency\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n    \noutput = pods_for_namespace(start_time, '$namespace')\noutput.rss = output.rss / px.pow(2,20)\noutput.vsize = output.vsize / px.pow(2,20)\n\noutput.phase = px.pluck(output.status, \"phase\") \noutput.ready = px.pluck(output.status, \"ready\") \n\noutput = output[['pod', 'phase', 'ready', 'rss', 'vsize', 'create_time']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Pod List",
          "type": "table"
        }
      ],
      "schemaVersion": 36,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {},
            "datasource": {
              "type": "pixie-pixie-datasource",
              "uid": "pixie"
            },
            "definition": "Clusters",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieCluster",
            "options": [],
            "query": {
              "queryType": "get-clusters"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          },
          {
            "current": {},
            "datasource": {
              "type": "pixie-pixie-datasource",
              "uid": "pixie"
            },
            "definition": "Namespaces",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "namespace",
            "options": [],
            "query": {
              "queryBody": {
                "clusterID": "$pixieCluster"
              },
              "queryType": "get-namespaces"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Pixie Namespace Overview",
      "description": "Dashboard includes a service map of the HTTP traffic between the services in the selected namspace, along with the latency, error rate, and throughput per service. It also lists pods available in the namespace. To learn how to monitor service performance and infrastructure health using Pixie, see https://docs.px.dev/tutorials/pixie-101/service-performance/",
      "uid": "F6XZR_j7k",
      "version": 1,
      "weekStart": ""
    }
    `}}
  pixie-node.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "DS_PIXIE_GRAFANA DATASOURCE PLUGIN",
          "label": "Pixie Grafana Datasource Plugin",
          "description": "",
          "type": "datasource",
          "pluginId": "pixie-pixie-datasource",
          "pluginName": "Pixie Grafana Datasource Plugin"
        }
      ],
      "__requires": [
        {
          "type": "datasource",
          "id": "pixie-pixie-datasource",
          "name": "Pixie Grafana Datasource Plugin",
          "version": "0.0.9"
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        },
        {
          "type": "panel",
          "id": "timeseries",
          "name": "Time series",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1657153861516,
      "links": [],
      "panels": [
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "phase"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "ready"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "start_time"
                },
                "properties": [
                  {
                    "id": "custom.align",
                    "value": "right"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.pod}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 13,
            "w": 16,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = pods_for_node(start_time, node)\noutput.phase = px.pluck(output.status, \"phase\") \noutput.ready = px.pluck(output.status, \"ready\") \n\n\noutput = output[['pod', 'phase', 'ready', 'start_time', 'containers']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Pods",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "CPU Usage",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "percentunit"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 16,
            "y": 0
          },
          "id": 3,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = resource_timeseries(start_time, node, '$groupby')\n#output.phase = px.pluck(output.status, \"phase\") \n#output.ready = px.pluck(output.status, \"ready\") \noutput = output[['time_', 'cpu_usage','groupby_col']]\n\n#output = output[['pod', 'phase', 'ready', 'start_time', 'containers']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "CPU Usage",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Bytes Read",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 0,
            "y": 13
          },
          "id": 4,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = resource_timeseries(start_time, node, '$groupby')\n#output.phase = px.pluck(output.status, \"phase\") \n#output.ready = px.pluck(output.status, \"ready\") \noutput.bytes_read = output.total_disk_read_throughput * px.pow(10,9) / px.pow(2,10)\noutput = output[['time_', 'bytes_read','groupby_col']]\n\n#output = output[['pod', 'phase', 'ready', 'start_time', 'containers']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Bytes Read",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Bytes Written",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 8,
            "y": 13
          },
          "id": 5,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = resource_timeseries(start_time, node, '$groupby')\n#output.phase = px.pluck(output.status, \"phase\") \n#output.ready = px.pluck(output.status, \"ready\") \noutput.bytes_written = output.total_disk_write_throughput * px.pow(10,9) / px.pow(2,10)\noutput = output[['time_', 'bytes_written','groupby_col']]\n\n#output = output[['pod', 'phase', 'ready', 'start_time', 'containers']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Bytes Written",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Bytes Read",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 16,
            "y": 13
          },
          "id": 6,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = network_stats(start_time, node, '$groupby')\noutput.sent_data = output.tx_bytes_per_ns * px.pow(10,9) / px.pow(2,10)\noutput = output[['time_', 'sent_data','groupby_col']]\n\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Bytes Read",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Received Data",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 11,
            "w": 8,
            "x": 0,
            "y": 25
          },
          "id": 7,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = network_stats(start_time, node, '$groupby')\noutput.received_data = output.rx_bytes_per_ns * px.pow(10,9) / px.pow(2,10)\noutput = output[['time_', 'received_data','groupby_col']]\n\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Received Network Traffic",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Resident Memory Usage",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "deckbytes"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 11,
            "w": 8,
            "x": 8,
            "y": 25
          },
          "id": 8,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = resource_timeseries(start_time, node, '$groupby')\noutput.rss = output.rss / px.pow(2,10)\noutput = output[['time_', 'rss','groupby_col']]\n\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Resident Set Size",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Virtual Memory Usage",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [
                {
                  "options": {
                    "Failed": {
                      "color": "red",
                      "index": 5
                    },
                    "Pending": {
                      "color": "yellow",
                      "index": 6
                    },
                    "Running": {
                      "color": "green",
                      "index": 0
                    },
                    "Succeeded": {
                      "color": "green",
                      "index": 4
                    },
                    "Terminated": {
                      "color": "red",
                      "index": 3
                    },
                    "Unknown": {
                      "color": "red",
                      "index": 7
                    },
                    "Waiting": {
                      "color": "yellow",
                      "index": 8
                    },
                    "false": {
                      "color": "red",
                      "index": 2
                    },
                    "true": {
                      "color": "green",
                      "index": 1
                    }
                  },
                  "type": "value"
                }
              ],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "deckbytes"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 11,
            "w": 8,
            "x": 16,
            "y": 25
          },
          "id": 9,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Node Overview\n\nThis view summarizes the process and network stats for a given input node in a cluster.\nIt computes CPU, memory consumption, as well as network traffic statistics.\nIt also displays a list of pods that were on that node during the time window.\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n\n# $pixieCluster - work around for grafana to update panel on variable change\nnode = '$node'\nstart_time = __time_from\n\ndef pods_for_node(start_time: int, node: px.Node):\n    ''' Gets a list of pods running on the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df.pod = df.ctx['pod_name']\n    df.container = df.ctx['container_name']\n    df = df.groupby(['pod', 'container']).agg()\n    df = df.groupby('pod').agg(containers=('container', px.count))\n    df.start_time = px.pod_name_to_start_time(df.pod)\n    df.status = px.pod_name_to_status(df.pod)\n    return df[['pod', 'start_time', 'containers', 'status']]\n\n\ndef resource_timeseries(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the windowed process stats (CPU, memory, etc) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['node_name'] == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'timestamp', groupby]).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', groupby]).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    df.groupby_col = df[groupby]\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp', groupby])\n\n\ndef network_stats(start_time: int, node: px.Node, groupby: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[px.pod_id_to_node_name(df.pod_id) == node]\n    df[groupby] = df.ctx[groupby]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id', groupby]).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp', groupby]).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df.groupby_col = df[groupby]\n    df['time_'] = df['timestamp']\n    return df.drop(['timestamp', groupby])\n\n\ndef stacktraces(start_time: int, node: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Compute node using _exec_hostname() instead of 'df.ctx['node']'\n    # We do this so it works for non-k8s processes too.\n    # This is important for determining total number of stack trace samples per node,\n    # as we need to include the non-K8s processes in the computation.\n    df.node = px.Node(px._exec_hostname())\n\n    # When computing percentages below, we want CPU percentages, not Node percentages.\n    # Since a node may have multiple CPUs, the formula is:\n    #    percentage = num_samples_symbol / (num_samples_node / num_cpus )\n    # So grab the number of CPUs and pipe it down to the percentage computation.\n    df.num_cpus = px._exec_host_num_cpus()\n\n    # Filter on the node.\n    df = df[df.node == node]\n\n    # Get stack trace totals for this node.\n    # Do this before any additional filtering.\n    node_agg = df.groupby([\"node\"]).agg(\n        count=('count', px.sum),\n        num_cpus=('num_cpus', px.any)\n    )\n\n    # Filter out non-k8s processes.\n    df = df[df.pod != '']\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['node', 'namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        node_agg,\n        how='inner',\n        left_on=\"node\",\n        right_on=\"node\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count * df.num_cpus / df.count_x\n    return df.drop('node_x')\n\noutput = resource_timeseries(start_time, node, '$groupby')\noutput.vsize = output.vsize / px.pow(2,10)\noutput = output[['time_', 'vsize','groupby_col']]\n\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Virtual Memory Size",
          "type": "timeseries"
        }
      ],
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Clusters",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieCluster",
            "options": [],
            "query": {
              "queryType": "get-clusters"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          },
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Node",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "node",
            "options": [],
            "query": {
              "queryBody": {
                "clusterID": "$pixieCluster"
              },
              "queryType": "get-nodes"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          },
          {
            "current": {
              "selected": false,
              "text": "node",
              "value": "node"
            },
            "description": "",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "groupby",
            "options": [
              {
                "selected": true,
                "text": "node",
                "value": "node"
              },
              {
                "selected": false,
                "text": "service",
                "value": "service"
              },
              {
                "selected": false,
                "text": "pod",
                "value": "pod"
              },
              {
                "selected": false,
                "text": "namespace",
                "value": "namespace"
              }
            ],
            "query": "node,service,pod,namespace",
            "queryValue": "",
            "skipUrlSync": false,
            "type": "custom"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Pixie Node Overview",
      "description": "Dashboard shows the pods on the selected node along with their CPU usage, memory consumption, and network traffic stats. To learn how to monitor infrastructure health using Pixie, see https://docs.px.dev/tutorials/pixie-101/infra-health/",
      "uid": "tcpoz_jnz",
      "version": 1,
      "weekStart": ""
    }
    `}}
  pixie-pod.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "DS_PIXIE_GRAFANA DATASOURCE PLUGIN",
          "label": "Pixie Grafana Datasource Plugin",
          "description": "",
          "type": "datasource",
          "pluginId": "pixie-pixie-datasource",
          "pluginName": "Pixie Grafana Datasource Plugin"
        }
      ],
      "__requires": [
        {
          "type": "datasource",
          "id": "pixie-pixie-datasource",
          "name": "Pixie Grafana Datasource Plugin",
          "version": "0.0.9"
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        },
        {
          "type": "panel",
          "id": "timeseries",
          "name": "Time series",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1657153831003,
      "links": [],
      "liveNow": false,
      "panels": [
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "request throughput",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "/s"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable changes\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = inbound_request_timeseries_by_container(start_time, pod)\noutput.request_throughput = output.request_throughput * px.pow(10,9)\npx.display(output[['time_', 'request_throughput', 'container']])"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Requests",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "error rate",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "/s"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 8,
            "y": 0
          },
          "id": 4,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = inbound_request_timeseries_by_container(start_time, pod)\noutput.errors_per_ns = output.errors_per_ns * px.pow(10,9)\npx.display(output[['time_', 'errors_per_ns', 'container']])"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Errors",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisGridShow": true,
                "axisLabel": "milliseconds",
                "axisPlacement": "auto",
                "axisSoftMax": 6,
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 16,
            "y": 0
          },
          "id": 10,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = inbound_latency_timeseries(start_time, pod)\noutput.latency_p50 = output.latency_p50 / px.pow(10,6)\noutput.latency_p90 = output.latency_p90 / px.pow(10,6)\noutput.latency_p99 = output.latency_p99 / px.pow(10,6)\n\npx.display(output[['time_', 'latency_p50', 'latency_p90', 'latency_p99']])"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Latency",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "CPU Usage",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "percent"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 0,
            "y": 13
          },
          "id": 6,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = resource_timeseries(start_time, pod)\noutput.cpu_usage_percent = output.cpu_usage * 100\npx.display(output[['time_', 'cpu_usage_percent', 'container']])"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "CPU Usage",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "state"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 131
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "mappings",
                    "value": [
                      {
                        "options": {
                          "Failed": {
                            "color": "red",
                            "index": 5
                          },
                          "Pending": {
                            "color": "yellow",
                            "index": 6
                          },
                          "Running": {
                            "color": "green",
                            "index": 0
                          },
                          "Succeeded": {
                            "color": "green",
                            "index": 4
                          },
                          "Terminated": {
                            "color": "red",
                            "index": 3
                          },
                          "Unknown": {
                            "color": "red",
                            "index": 7
                          },
                          "Waiting": {
                            "color": "yellow",
                            "index": 8
                          },
                          "false": {
                            "color": "red",
                            "index": 2
                          },
                          "true": {
                            "color": "green",
                            "index": 1
                          }
                        },
                        "type": "value"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "ready"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 97
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "name"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 102
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "message"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 84
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 8,
            "y": 13
          },
          "id": 8,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = containers(start_time, pod)\n\noutput.state = px.pluck(output.status, \"state\") \noutput.message = px.pluck(output.status, \"ready\") \n\noutput = output[['name', 'state', 'message', 'id']]\n\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Container List",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "pid"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 118
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "cmd"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 321
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 16,
            "y": 13
          },
          "id": 12,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = processes(start_time, pod)\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Process List",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Network Throughput",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 0,
            "y": 25
          },
          "id": 15,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = network_timeseries(start_time, pod)\noutput.rx_bytes_per_ns = output.rx_bytes_per_ns * px.pow(10, 9) / px.pow(2,10)\noutput.tx_bytes_per_ns = output.tx_bytes_per_ns * px.pow(10, 9) / px.pow(2,10)\noutput = output[['time_', 'rx_bytes_per_ns', 'tx_bytes_per_ns']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Network Sent And Received",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Disk Read Throughput",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 8,
            "y": 25
          },
          "id": 16,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": ".05# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = resource_timeseries(start_time, pod)\noutput.total_disk_read_throughput = output.total_disk_read_throughput * px.pow(10,9) / px.pow(2,10)\noutput = output[['time_', 'total_disk_read_throughput', 'container']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Bytes Read",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "Disk Write Throughput",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "binBps"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 16,
            "y": 25
          },
          "id": 17,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = resource_timeseries(start_time, pod)\noutput.total_disk_write_throughput = output.total_disk_write_throughput * px.pow(10,9)\noutput = output[['time_', 'total_disk_write_throughput', 'container']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Bytes Written",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "RSS",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "decmbytes"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 0,
            "y": 38
          },
          "id": 18,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = resource_timeseries(start_time, pod)\noutput.rss = output.rss / px.pow(2,20)\noutput = output[['time_', 'rss', 'container']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Resident Set Size",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "vsize",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "decmbytes"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 8,
            "y": 38
          },
          "id": 19,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = resource_timeseries(start_time, pod)\noutput.vsize = output.vsize / px.pow(2,20)\noutput = output[['time_', 'vsize', 'container']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Virtual Memory Size",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "latency_p99"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green"
                        },
                        {
                          "color": "light-orange",
                          "value": 150
                        },
                        {
                          "color": "red",
                          "value": 300
                        }
                      ]
                    }
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  },
                  {
                    "id": "unit",
                    "value": "ms"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "error_rate"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "percentunit"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "request_throughput"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "/s"
                  },
                  {
                    "id": "decimals",
                    "value": 1
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "requesting_pod"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.requesting_pod}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "requesting_svc"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/qhHtFyCnk/px-service?orgId=1&${pixieCluster:queryparam}&var-pixieService=${__data.fields.requesting_svc}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 10,
            "w": 24,
            "x": 0,
            "y": 51
          },
          "id": 20,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "error_rate"
              }
            ]
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = inbound_let_summary(start_time, pod)\noutput.latency_p99 = px.pluck_float64(output.latency, \"p99\") / px.pow(10,6)\noutput.request_throughput = output.request_throughput * px.pow(10,9)\noutput = output[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency_p99', 'error_rate', 'request_throughput']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Inbound HTTP Traffic To Pod",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "description": "",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "phase"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "mappings",
                    "value": [
                      {
                        "options": {
                          "Running": {
                            "color": "green",
                            "index": 0
                          }
                        },
                        "type": "value"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "ready"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "mappings",
                    "value": [
                      {
                        "options": {
                          "false": {
                            "color": "red",
                            "index": 1
                          },
                          "true": {
                            "color": "green",
                            "index": 0
                          }
                        },
                        "type": "value"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "node"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/tcpoz_jnz/px-node?orgId=1&${pixieCluster:queryparam}&var-node=${__data.fields.node}&var-groupby=node"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "service"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/qhHtFyCnk/px-service?orgId=1&${pixieCluster:queryparam}&var-pixieService=${__data.fields.service}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 8,
            "w": 24,
            "x": 0,
            "y": 61
          },
          "id": 21,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n'''Pod Overview\n\nOverview of a specific Pod monitored by Pixie with its high level application metrics\n(latency, error-rate & rps) and resource usage (cpu, writes, reads).\n\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\npod = \"$pixiePod\"\n\ndef containers(start_time: int, pod: str):\n    ''' A list of containers in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.name = df.ctx['container_name']\n    df.id = df.ctx['container_id']\n    df = df.groupby(['name', 'id']).agg()\n    df.status = px.container_id_to_status(df.id)\n    return df\n\n\ndef node(start_time: int, pod: str):\n    ''' A list containing the node the 'pod' is running on.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.node = df.ctx['node_name']\n    df.service = df.ctx['service']\n    df.pod_id = df.ctx['pod_id']\n    df.pod_name = df.ctx['pod']\n    df = df.groupby(['node', 'service', 'pod_id', 'pod_name']).agg()\n    df.pod_start_time = px.pod_name_to_start_time(df.pod_name)\n    df.status = px.pod_name_to_status(df.pod_name)\n    return df.drop('pod_name')\n\n\ndef processes(start_time: int, pod: str):\n    ''' A list of processes in 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.cmd = df.ctx['cmdline']\n    df.pid = df.ctx['pid']\n    df = df.groupby(['pid', 'cmd', 'upid']).agg()\n    return df\n\n\ndef resource_timeseries(start_time: int, pod: str):\n    ''' Compute the resource usage as a timeseries for 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.container = df.ctx['container_name']\n\n    # First calculate CPU usage by process (UPID) in each k8s_object\n    # over all windows.\n    df = df.groupby(['upid', 'container', 'timestamp']).agg(\n        rss=('rss_bytes', px.mean),\n        vsize=('vsize_bytes', px.mean),\n        # The fields below are counters, so we take the min and the max to subtract them.\n        cpu_utime_ns_max=('cpu_utime_ns', px.max),\n        cpu_utime_ns_min=('cpu_utime_ns', px.min),\n        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),\n        cpu_ktime_ns_min=('cpu_ktime_ns', px.min),\n        read_bytes_max=('read_bytes', px.max),\n        read_bytes_min=('read_bytes', px.min),\n        write_bytes_max=('write_bytes', px.max),\n        write_bytes_min=('write_bytes', px.min),\n        rchar_bytes_max=('rchar_bytes', px.max),\n        rchar_bytes_min=('rchar_bytes', px.min),\n        wchar_bytes_max=('wchar_bytes', px.max),\n        wchar_bytes_min=('wchar_bytes', px.min),\n    )\n\n    # Next calculate cpu usage and memory stats per window.\n    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min\n    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min\n    df.actual_disk_read_throughput = (df.read_bytes_max - df.read_bytes_min) / window_ns\n    df.actual_disk_write_throughput = (df.write_bytes_max - df.write_bytes_min) / window_ns\n    df.total_disk_read_throughput = (df.rchar_bytes_max - df.rchar_bytes_min) / window_ns\n    df.total_disk_write_throughput = (df.wchar_bytes_max - df.wchar_bytes_min) / window_ns\n\n    # Then aggregate process individual process metrics.\n    df = df.groupby(['timestamp', 'container']).agg(\n        cpu_ktime_ns=('cpu_ktime_ns', px.sum),\n        cpu_utime_ns=('cpu_utime_ns', px.sum),\n        actual_disk_read_throughput=('actual_disk_read_throughput', px.sum),\n        actual_disk_write_throughput=('actual_disk_write_throughput', px.sum),\n        total_disk_read_throughput=('total_disk_read_throughput', px.sum),\n        total_disk_write_throughput=('total_disk_write_throughput', px.sum),\n        rss=('rss', px.sum),\n        vsize=('vsize', px.sum),\n    )\n\n    # Finally, calculate total (kernel + user time)  percentage used over window.\n    df.cpu_usage = px.Percent((df.cpu_ktime_ns + df.cpu_utime_ns) / window_ns)\n    df['time_'] = df['timestamp']\n    return df.drop(['cpu_ktime_ns', 'cpu_utime_ns', 'timestamp'])\n\n\ndef network_timeseries(start_time: int, pod: str):\n    ''' Gets the network stats (transmitted/received traffic) for the input node.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @node: The full name of the node to filter on.\n    '''\n    df = px.DataFrame(table='network_stats', start_time=start_time)\n    df = df[df.ctx['pod'] == pod]\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    # First calculate network usage by node over all windows.\n    # Data is sharded by Pod in network_stats.\n    df = df.groupby(['timestamp', 'pod_id']).agg(\n        rx_bytes_end=('rx_bytes', px.max),\n        rx_bytes_start=('rx_bytes', px.min),\n        tx_bytes_end=('tx_bytes', px.max),\n        tx_bytes_start=('tx_bytes', px.min),\n        tx_errors_end=('tx_errors', px.max),\n        tx_errors_start=('tx_errors', px.min),\n        rx_errors_end=('rx_errors', px.max),\n        rx_errors_start=('rx_errors', px.min),\n        tx_drops_end=('tx_drops', px.max),\n        tx_drops_start=('tx_drops', px.min),\n        rx_drops_end=('rx_drops', px.max),\n        rx_drops_start=('rx_drops', px.min),\n    )\n\n    # Calculate the network statistics rate over the window.\n    # We subtract the counter value at the beginning ('_start')\n    # from the value at the end ('_end').\n    df.rx_bytes_per_ns = (df.rx_bytes_end - df.rx_bytes_start) / window_ns\n    df.tx_bytes_per_ns = (df.tx_bytes_end - df.tx_bytes_start) / window_ns\n    df.rx_drops_per_ns = (df.rx_drops_end - df.rx_drops_start) / window_ns\n    df.tx_drops_per_ns = (df.tx_drops_end - df.tx_drops_start) / window_ns\n    df.rx_errors_per_ns = (df.rx_errors_end - df.rx_errors_start) / window_ns\n    df.tx_errors_per_ns = (df.tx_errors_end - df.tx_errors_start) / window_ns\n\n    # Add up the network values per node.\n    df = df.groupby(['timestamp']).agg(\n        rx_bytes_per_ns=('rx_bytes_per_ns', px.sum),\n        tx_bytes_per_ns=('tx_bytes_per_ns', px.sum),\n        rx_drop_per_ns=('rx_drops_per_ns', px.sum),\n        tx_drops_per_ns=('tx_drops_per_ns', px.sum),\n        rx_errors_per_ns=('rx_errors_per_ns', px.sum),\n        tx_errors_per_ns=('tx_errors_per_ns', px.sum),\n    )\n    df['time_'] = df['timestamp']\n    return df\n\n\ndef inbound_latency_timeseries(start_time: int, pod: str):\n    ''' Compute the latency as a timeseries for requests received by 'pod'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.time_ = df.timestamp\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\n\ndef inbound_request_timeseries_by_container(start_time: int, pod: str):\n    ''' Compute the request statistics as a timeseries for requests received\n        by 'pod' by container.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @pod: The name of the pod to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n    df.container = df.ctx['container']\n\n    df = df.groupby(['timestamp', 'container']).agg(\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.time_ = df.timestamp\n\n    return df[['time_', 'container', 'request_throughput', 'errors_per_ns', 'error_rate']]\n\n\ndef inbound_let_summary(start_time: int, pod: str):\n    ''' Gets a summary of requests inbound to 'pod'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @pod: The pod to filter on.\n    '''\n    df = let_helper(start_time)\n    df = df[df.pod == pod]\n\n    quantiles_agg = df.groupby(['pod', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n    )\n\n    quantiles_table = quantiles_agg[['pod', 'remote_addr', 'latency',\n                                     'total_request_count']]\n\n    range_agg = df.groupby(['pod', 'remote_addr', 'timestamp']).agg(\n        requests_per_window=('time_', px.count),\n        error_rate=('failure', px.mean)\n    )\n\n    rps_table = range_agg.groupby(['pod', 'remote_addr']).agg(\n        requests_per_window=('requests_per_window', px.mean),\n        error_rate=('error_rate', px.mean)\n    )\n\n    joined_table = quantiles_table.merge(rps_table,\n                                         how='inner',\n                                         left_on=['pod', 'remote_addr'],\n                                         right_on=['pod', 'remote_addr'],\n                                         suffixes=['', '_x'])\n\n    joined_table.error_rate = px.Percent(joined_table.error_rate)\n    joined_table.request_throughput = joined_table.requests_per_window / window_ns\n\n    joined_table.responder = df.pod\n    joined_table.requesting_ip = df.remote_addr\n    joined_table.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    joined_table.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return joined_table[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency',\n                         'error_rate', 'request_throughput']]\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by pod is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    df.pod = df.ctx['pod']\n    df.timestamp = px.bin(df.time_, window_ns)\n    df.failure = df.resp_status >= 400\n\n    # Filter only to inbound pod traffic (server-side).\n    # Don't include traffic initiated by this pod to an external location.\n    df = df[df.trace_role == 2]\n\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n    df = df[filter_out_conds]\n\n    return df\n\n\ndef stacktraces(start_time: int, pod: str):\n    df = px.DataFrame(table='stack_traces.beta', start_time=start_time)\n\n    df.namespace = df.ctx['namespace']\n    df.pod = df.ctx['pod']\n    df.container = df.ctx['container']\n    df.cmdline = df.ctx['cmdline']\n\n    # Filter on the pod.\n    df = df[df.pod == pod]\n\n    # Get stack trace totals for the pod.\n    # This must be done before any additional filtering to avoid skewing percentages.\n    grouping_agg = df.groupby([\"pod\"]).agg(\n        count=('count', px.sum)\n    )\n\n    # Combine flamegraphs from different intervals into one larger framegraph.\n    df = df.groupby(['namespace', 'pod', 'container', 'cmdline', 'stack_trace_id']).agg(\n        stack_trace=('stack_trace', px.any),\n        count=('count', px.sum)\n    )\n\n    # Compute percentages.\n    df = df.merge(\n        grouping_agg,\n        how='inner',\n        left_on=\"pod\",\n        right_on=\"pod\",\n        suffixes=['', '_x']\n    )\n    df.percent = 100.0 * df.count / df.count_x\n    df.drop('pod_x')\n\n    return df\n\noutput = node(start_time, pod)\noutput.phase = px.pluck(output.status, \"phase\")\noutput.ready = px.pluck(output.status, \"ready\")\noutput = output[['node', 'phase', 'ready', 'service', 'pod_id', 'pod_start_time']]\npx.display(output)"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Pod Metadata",
          "type": "table"
        }
      ],
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Clusters",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieCluster",
            "options": [],
            "query": {
              "queryType": "get-clusters"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          },
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Pods",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixiePod",
            "options": [],
            "query": {
              "queryBody": {
                "clusterID": "$pixieCluster"
              },
              "queryType": "get-pods"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Pixie Pod Overview",
      "description": "Dashboard shows an overview of the specified pod, including high-level HTTP application metrics, and resource usage. To learn how to monitor infrastructure health using Pixie, see https://docs.px.dev/tutorials/pixie-101/infra-health/",
      "uid": "_t3foxCnz",
      "version": 1,
      "weekStart": ""
    }
    `}}
  pixie-service.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "DS_PIXIE_GRAFANA DATASOURCE PLUGIN",
          "label": "Pixie Grafana Datasource Plugin",
          "description": "",
          "type": "datasource",
          "pluginId": "pixie-pixie-datasource",
          "pluginName": "Pixie Grafana Datasource Plugin"
        }
      ],
      "__requires": [
        {
          "type": "datasource",
          "id": "pixie-pixie-datasource",
          "name": "Pixie Grafana Datasource Plugin",
          "version": "0.0.9"
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        },
        {
          "type": "panel",
          "id": "timeseries",
          "name": "Time series",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1657153808544,
      "links": [],
      "liveNow": false,
      "panels": [
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "request throughput",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "/s"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = inbound_let_timeseries(start_time, service)\noutput.request_throughput = output.request_throughput * px.pow(10,9)\noutput = output[['time_', 'request_throughput']]\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Requests",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "error rate",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "/s"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 8,
            "y": 0
          },
          "id": 3,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = inbound_let_timeseries(start_time, service)\noutput.errors_per_ns = output.errors_per_ns * px.pow(10,9)\noutput = output[['time_', 'errors_per_ns']]\n\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Errors",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "latency",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 12,
            "w": 8,
            "x": 16,
            "y": 0
          },
          "id": 4,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = inbound_let_timeseries(start_time, service)\noutput.latency_p50 = output.latency_p50 / px.pow(10,6)\noutput.latency_p90 = output.latency_p90 / px.pow(10,6)\noutput.latency_p99 = output.latency_p99 / px.pow(10,6)\noutput = output[['time_', 'latency_p50', 'latency_p90', 'latency_p99']]\n\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Latency",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisLabel": "response data throughput",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "KBs"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 13,
            "w": 8,
            "x": 0,
            "y": 12
          },
          "id": 5,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom"
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = inbound_let_timeseries(start_time, service)\noutput.bytes_per_ns = output.bytes_per_ns * px.pow(10,9) / px.pow(2,10)\noutput = output[['time_', 'bytes_per_ns']]\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "HTTP Response Data Throughput",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "/s"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "state"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 127
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "mappings",
                    "value": [
                      {
                        "options": {
                          "Failed": {
                            "color": "red",
                            "index": 5
                          },
                          "Pending": {
                            "color": "yellow",
                            "index": 6
                          },
                          "Running": {
                            "color": "green",
                            "index": 0
                          },
                          "Succeeded": {
                            "color": "green",
                            "index": 4
                          },
                          "Terminated": {
                            "color": "red",
                            "index": 3
                          },
                          "Unknown": {
                            "color": "red",
                            "index": 7
                          },
                          "Waiting": {
                            "color": "yellow",
                            "index": 8
                          },
                          "false": {
                            "color": "red",
                            "index": 2
                          },
                          "true": {
                            "color": "green",
                            "index": 1
                          }
                        },
                        "type": "value"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "message"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 214
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.pod}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 13,
            "w": 16,
            "x": 8,
            "y": 12
          },
          "id": 6,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = pods_for_service(start_time, service)\n\noutput.state = px.pluck(output.pod_status, \"phase\")\noutput.message = px.pluck(output.pod_status, \"message\") \n\noutput = output[['pod', 'state', 'message', 'pod_create_time']]\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Pod List",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "error_rate"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "percentunit"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "latency_p99"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "ms"
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green"
                        },
                        {
                          "color": "light-orange",
                          "value": 150
                        },
                        {
                          "color": "red",
                          "value": 300
                        }
                      ]
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "requesting_pod"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.requesting_pod}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "requesting_svc"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/qhHtFyCnk/px-service?orgId=1&${pixieCluster:queryparam}&var-pixieService=${__data.fields.requesting_svc}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 14,
            "w": 24,
            "x": 0,
            "y": 25
          },
          "id": 7,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "latency_p99"
              }
            ]
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = inbound_let_summary(start_time, service)\noutput.latency_p99 = px.pluck_float64(output.latency, \"p99\") / px.pow(10,6)\n\noutput = output[['requesting_ip', 'requesting_pod', 'requesting_svc', 'latency_p99', 'error_rate']]\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Inbound HTTP Traffic To Service",
          "type": "table"
        },
        {
          "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green"
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "latency"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "ms"
                  },
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "light-green"
                        },
                        {
                          "color": "light-orange",
                          "value": 150
                        },
                        {
                          "color": "red",
                          "value": 300
                        }
                      ]
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "resp_status"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "color-text"
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green"
                        },
                        {
                          "color": "yellow",
                          "value": 300
                        },
                        {
                          "color": "red",
                          "value": 400
                        }
                      ]
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "pod"
                },
                "properties": [
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "",
                        "url": "/d/_t3foxCnz/px-pod?orgId=1&${pixieCluster:queryparam}&var-pixiePod=${__data.fields.pod}"
                      }
                    ]
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 24,
            "w": 24,
            "x": 0,
            "y": 39
          },
          "id": 8,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "latency"
              }
            ]
          },
          "pluginVersion": "7.5.1",
          "targets": [
            {
              "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
              "queryBody": {
                "pxlScript": "# Copyright 2018- The Pixie Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\n''' Service Overview\n\n This script gets an overview of an individual service, summarizing its request statistics.\n'''\nimport px\n\nns_per_ms = 1000 * 1000\nns_per_s = 1000 * ns_per_ms\n# Window size to use on time_ column for bucketing.\nwindow_ns = px.DurationNanos(10 * ns_per_s)\n# Flag to filter out requests that come from an unresolvable IP.\nfilter_unresolved_inbound = True\n# Flag to filter out health checks from the data.\nfilter_health_checks = True\n# Flag to filter out ready checks from the data.\nfilter_ready_checks = True\n\n# $pixieCluster - work around for grafana to update panel on variable change\n\nstart_time = __time_from\nservice = \"$pixieService\"\n\ndef pods_for_service(start_time: int, service: px.Service):\n    df = px.DataFrame(table='process_stats', start_time=start_time)\n    df = df[px.has_service_name(df.ctx['service'], service)]\n    df.pod = df.ctx['pod_name']\n    df = df.groupby('pod').agg()\n    df.pod_create_time = px.pod_name_to_start_time(df.pod)\n    df.pod_status = px.pod_name_to_status(df.pod)\n    return df\n\n\ndef inbound_let_timeseries(start_time: int, service: px.Service):\n    ''' Compute the let as a timeseries for requests received by 'service'.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n    @service: The name of the service to filter on.\n\n    '''\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n\n    df = df.groupby(['timestamp']).agg(\n        latency_quantiles=('latency', px.quantiles),\n        error_rate_per_window=('failure', px.mean),\n        throughput_total=('latency', px.count),\n        bytes_total=('resp_body_size', px.sum)\n    )\n\n    # Format the result of LET aggregates into proper scalar formats and\n    # time series.\n    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))\n    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))\n    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))\n    df.request_throughput = df.throughput_total / window_ns\n    df.errors_per_ns = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)\n    df.error_rate = px.Percent(df.error_rate_per_window)\n    df.bytes_per_ns = df.bytes_total / window_ns\n    df.time_ = df.timestamp\n\n    return df[['time_', 'latency_p50', 'latency_p90', 'latency_p99',\n               'request_throughput', 'errors_per_ns', 'error_rate', 'bytes_per_ns']]\n\n\ndef inbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests inbound to 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.responder, service)]\n    return df.drop('responder')\n\n\ndef outbound_let_summary(start_time: int, service: px.Service):\n    ''' Gets a summary of requests outbound from 'service'.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    @service: The service to filter on.\n    '''\n    df = let_summary_helper(start_time)\n    df = df[px.has_service_name(df.requestor, service)]\n    return df.drop(['requestor', 'remote_addr'])\n\n\ndef let_summary_helper(start_time: int):\n    ''' Gets a summary of request statistics. This is a helper function, filtering by\n        service is done elsewhere.\n\n    Args:\n    @start_time Starting time of the data to examine.\n    '''\n    df = let_helper(start_time)\n\n    df = df.groupby(['service', 'remote_addr']).agg(\n        latency=('latency', px.quantiles),\n        total_request_count=('latency', px.count)\n        error_rate=('failure', px.mean),\n    )\n\n    df.error_rate = px.Percent(df.error_rate)\n    df.responder = df.service\n    df.requesting_ip = df.remote_addr\n    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))\n    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))\n\n    return df[['responder', 'requesting_ip', 'requesting_pod', 'requesting_svc',\n               'latency', 'error_rate']]\n\n\ndef service_slow_requests(start_time: int, service: px.Service):\n    df = let_helper(start_time)\n    df = df[px.has_service_name(df.service, service)]\n    quantiles = df.groupby('service').agg(\n        latency_quantiles=('latency', px.quantiles)\n    )\n    quantiles.service_p99 = px.pluck_float64(quantiles.latency_quantiles, 'p99')\n    quantiles = quantiles.drop('latency_quantiles')\n    requests = df.merge(quantiles, left_on='service', right_on='service', how='inner',\n                        suffixes=['', '_x'])\n    requests = requests[requests.latency >= px.floor(requests.service_p99)]\n\n    return requests[['time_', 'pod', 'latency', 'req_method',\n                     'req_path', 'req_body', 'resp_status',\n                     'remote_addr', 'remote_port',\n                     'resp_body']].head(100)\n\n\ndef let_helper(start_time: int):\n    ''' Compute the initial part of the let for requests.\n        Filtering to inbound/outbound traffic by service is done by the calling function.\n\n    Args:\n    @start_time: The timestamp of data to start at.\n\n    '''\n    df = px.DataFrame(table='http_events', start_time=start_time)\n    # Filter only to inbound service traffic (server-side).\n    # Don't include traffic initiated by this service to an external location.\n    df = df[df.trace_role == 2]\n    df.service = df.ctx['service']\n    df.pod = df.ctx['pod']\n    df.latency = df.latency\n\n    df.timestamp = px.bin(df.time_, window_ns)\n\n    df.failure = df.resp_status >= 400\n    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (\n        df.req_path != '/readyz' or not filter_ready_checks)) and (\n        df['remote_addr'] != '-' or not filter_unresolved_inbound)\n\n    df = df[filter_out_conds]\n    return df\n  \noutput = service_slow_requests(start_time, service)\noutput.latency = output.latency / px.pow(10,6)\noutput.timestamp = output.time_\noutput = output.drop('time_')\n\noutput = output[['timestamp', 'pod', 'latency', 'req_method', 'req_path', 'req_body', 'resp_status', 'remote_addr', 'remote_port', 'resp_body']]\npx.display(output)\n"
              },
              "queryType": "run-script",
              "refId": "A"
            }
          ],
          "title": "Sample Of Slow Inbound Requests",
          "type": "table"
        }
      ],
      "schemaVersion": 36,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Clusters",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieCluster",
            "options": [],
            "query": {
              "queryType": "get-clusters"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          },
          {
            "current": {},
            "datasource": {
            "type": "pixie-pixie-datasource",
            "uid": "pixie"
          },
            "definition": "Services",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "pixieService",
            "options": [],
            "query": {
              "queryBody": {
                "clusterID": "$pixieCluster"
              },
              "queryType": "get-services"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "type": "query"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Pixie Service Overview",
      "description": "Dashboard shows latency, error, and throughput over time for all HTTP requests for the selected service. It also includes a sample of slow requests to the service. To learn how to monitor service performance using Pixie, see https://docs.px.dev/tutorials/pixie-101/service-performance/",
      "uid": "qhHtFyCnk",
      "version": 1,
      "weekStart": ""
    }
    `}}
  demo-dashboard.json: |
    {{`
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "links": [],
      "liveNow": false,
      "panels": [
        {
          "collapsed": false,
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 14,
          "panels": [],
          "title": "Metrics",
          "type": "row"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "webstore-metrics"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "percent"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 1
          },
          "id": 6,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "expr": "rate(runtime_cpython_cpu_time{type=~\"system\"}[$__interval])*100",
              "legendFormat": "__auto",
              "range": true,
              "refId": "A"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "expr": "rate(runtime_cpython_cpu_time{type=~\"user\"}[$__interval])*100",
              "hide": false,
              "legendFormat": "__auto",
              "range": true,
              "refId": "B"
            }
          ],
          "title": "Recommendation Service (CPU%)",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "webstore-metrics"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "decmbytes"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 1
          },
          "id": 8,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "expr": "rate(runtime_cpython_memory{type=~\"rss|vms\"}[$__interval])/1024/1024",
              "legendFormat": "__auto",
              "range": true,
              "refId": "A"
            }
          ],
          "title": "Recommendation Service (Memory)",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "webstore-metrics"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "bars",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 9
          },
          "id": 4,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "expr": "rate(app_recommendations_counter{recommendation_type=\"catalog\"}[$__interval])",
              "legendFormat": "__auto",
              "range": true,
              "refId": "A"
            }
          ],
          "title": "Recommendations Count",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "webstore-metrics"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 9
          },
          "id": 10,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "expr": "rate(calls_total{status_code=\"STATUS_CODE_ERROR\"}[$__interval])",
              "legendFormat": "__auto",
              "range": true,
              "refId": "A"
            }
          ],
          "title": "Error Rate",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "webstore-metrics"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "dtdurationms"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 17
          },
          "id": 2,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "exemplar": true,
              "expr": "histogram_quantile(0.50, sum(rate(latency_bucket{service_name=\"${service}\"}[$__rate_interval])) by (le))",
              "legendFormat": "__auto",
              "range": true,
              "refId": "A"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "exemplar": false,
              "expr": "histogram_quantile(0.95, sum(rate(latency_bucket{service_name=\"${service}\"}[$__rate_interval])) by (le))",
              "hide": false,
              "legendFormat": "__auto",
              "range": true,
              "refId": "B"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "exemplar": false,
              "expr": "histogram_quantile(0.99, sum(rate(latency_bucket{service_name=\"${service}\"}[$__rate_interval])) by (le))",
              "hide": false,
              "legendFormat": "__auto",
              "range": true,
              "refId": "C"
            },
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "exemplar": false,
              "expr": "histogram_quantile(0.999, sum(rate(latency_bucket{service_name=\"${service}\"}[$__rate_interval])) by (le))",
              "hide": false,
              "legendFormat": "__auto",
              "range": true,
              "refId": "D"
            }
          ],
          "title": "Service Latency (from SpanMetrics)",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "webstore-metrics"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 0,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "reqps"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 17
          },
          "id": 12,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "webstore-metrics"
              },
              "editorMode": "code",
              "expr": "rate(latency_count{service_name=\"${service}\"}[$__rate_interval])",
              "legendFormat": "__auto",
              "range": true,
              "refId": "A"
            }
          ],
          "title": "Endpoint Rate by Service",
          "type": "timeseries"
        }
      ],
      "schemaVersion": 37,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "allValue": "",
            "current": {
              "selected": false,
              "text": "featureflagservice",
              "value": "featureflagservice"
            },
            "datasource": {
              "type": "prometheus",
              "uid": "webstore-metrics"
            },
            "definition": "latency_bucket",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "service",
            "options": [],
            "query": {
              "query": "latency_bucket",
              "refId": "StandardVariableQuery"
            },
            "refresh": 1,
            "regex": "/.*service_name=\\\"([^\\\"]+)\\\".*/",
            "skipUrlSync": false,
            "sort": 1,
            "type": "query"
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Prometheus Dashboard",
      "uid": "W2gX2zHVk",
      "version": 1,
      "weekStart": ""
    }
    `}}
  jaeger-dashboard.json: |
    {{`
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": 9,
      "links": [],
      "liveNow": false,
      "panels": [
        {
          "datasource": {
            "type": "jaeger",
            "uid": "webstore-traces"
          },
          "fieldConfig": {
            "defaults": {
              "custom": {
                "align": "auto",
                "displayMode": "auto",
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 15,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 1,
          "options": {
            "footer": {
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true
          },
          "pluginVersion": "9.3.8",
          "targets": [
            {
              "datasource": {
                "type": "jaeger",
                "uid": "webstore-traces"
              },
              "key": "Q-8fbc9ad8-d42d-48a9-be7a-df42fad2d7c2-0",
              "queryType": "search",
              "refId": "A",
              "service": "${service}"
            }
          ],
          "title": "Traces",
          "type": "table"
        }
      ],
      "schemaVersion": 37,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "allValue": "",
            "current": {
              "selected": false,
              "text": "featureflagservice",
              "value": "featureflagservice"
            },
            "datasource": {
              "type": "prometheus",
              "uid": "webstore-metrics"
            },
            "definition": "latency_bucket",
            "hide": 0,
            "includeAll": false,
            "multi": false,
            "name": "service",
            "options": [],
            "query": {
              "query": "latency_bucket",
              "refId": "StandardVariableQuery"
            },
            "refresh": 1,
            "regex": "/.*service_name=\\\"([^\\\"]+)\\\".*/",
            "skipUrlSync": false,
            "sort": 1,
            "type": "query"
          }
        ]
      },
      "time": {
        "from": "now-6h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Jaeger Dashboard",
      "uid": "HubIfRE4k",
      "version": 1,
      "weekStart": ""
    }
    `}}
  fluentbit-logs.json: |
    {{`
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "target": {
              "limit": 100,
              "matchAny": false,
              "tags": [],
              "type": "dashboard"
            },
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": 6,
      "links": [],
      "liveNow": false,
      "panels": [
        {
          "datasource": {
            "type": "loki",
            "uid": "P8E80F9AEF21F6940"
          },
          "gridPos": {
            "h": 21,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 1,
          "options": {
            "dedupStrategy": "none",
            "enableLogDetails": true,
            "prettifyLogMessage": true,
            "showCommonLabels": false,
            "showLabels": false,
            "showTime": true,
            "sortOrder": "Descending",
            "wrapLogMessage": false
          },
          "targets": [
            {
              "datasource": {
                "type": "loki",
                "uid": "P8E80F9AEF21F6940"
              },
              "editorMode": "builder",
              "expr": "{exporter=\"OTLP\"} | json",
              "key": "Q-f7b46c9f-da94-4e82-a9ec-66fa7794fa41-0",
              "queryType": "range",
              "refId": "A"
            }
          ],
          "title": "Logs",
          "type": "logs"
        }
      ],
      "schemaVersion": 37,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-5m",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Fluentbit Logs",
      "uid": "5VSvQgEVk",
      "version": 2,
      "weekStart": ""
    }
    `}}
  opentelemetry-collector.json: |
    {{`
    {
      "__inputs": [
        {
          "name": "webstore",
          "label": "Prometheus",
          "description": "",
          "type": "datasource",
          "pluginId": "prometheus",
          "pluginName": "Prometheus"
        }
      ],
      "__requires": [
        {
          "type": "grafana",
          "id": "grafana",
          "name": "Grafana",
          "version": "7.0.3"
        },
        {
          "type": "panel",
          "id": "graph",
          "name": "Graph",
          "version": ""
        },
        {
          "type": "datasource",
          "id": "prometheus",
          "name": "Prometheus",
          "version": "1.0.0"
        },
        {
          "type": "panel",
          "id": "stat",
          "name": "Stat",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "description": "Provides information about the status of the OpenTelemetry Collector",
      "editable": true,
      "gnetId": 12553,
      "graphTooltip": 0,
      "id": 22,
      "iteration": 1593502896956,
      "links": [],
      "panels": [
        {
          "collapsed": false,
          "datasource": "Prometheus",
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 23,
          "panels": [],
          "title": "Receivers",
          "type": "row"
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "description": "Rate of spans successfully accepted vs refused per second",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 0,
            "y": 1
          },
          "hiddenSeries": false,
          "id": 28,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_receiver_accepted_spans{receiver=~\"$receiver\"}[1m])) by (receiver)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{receiver}} spans accepted / sec",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_receiver_refused_spans{receiver=~\"$receiver\"}[1m])) by (receiver)",
              "interval": "",
              "legendFormat": "{{ receiver }} spans refused /sec",
              "refId": "B"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Spans Accepted vs Refused /Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "description": "Rate of metrics successfully accepted vs refused per second",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 12,
            "y": 1
          },
          "hiddenSeries": false,
          "id": 19,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_receiver_accepted_metric_points{receiver=~\"$receiver\"}[1m])) by (receiver)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{receiver}} accepted /sec",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_receiver_refused_metric_points{receiver=~\"$receiver\"}[1m])) by (receiver)",
              "interval": "",
              "legendFormat": "{{ receiver }} refused / sec",
              "refId": "B"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Metrics Accepted vs Refused Received/Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "collapsed": false,
          "datasource": "Prometheus",
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 10
          },
          "id": 25,
          "panels": [],
          "title": "Exporters",
          "type": "row"
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "description": "Rate of spans successfully exported vs Failed per second",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 0,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 0,
            "y": 11
          },
          "hiddenSeries": false,
          "id": 30,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_exporter_sent_spans{exporter=~\"$exporter\"}[1m])) by (exporter)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{exporter}} sent / sec",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_exporter_send_failed_spans{exporter=~\"$exporter\"}[1m])) by (exporter)",
              "interval": "",
              "legendFormat": "{{ exporter }} failed /sec",
              "refId": "B"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Spans Exported vs Failed / Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "description": "Rate of timeseries successfully exported per second",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 12,
            "y": 11
          },
          "hiddenSeries": false,
          "id": 31,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_exporter_sent_metric_points{exporter=~\"$exporter\"}[1m])) by (exporter)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{exporter}} sent /sec",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_exporter_send_failed_metric_points{exporter=~\"$exporter\"}[1m])) by (exporter)",
              "interval": "",
              "legendFormat": "{{ exporter }} failed / sec",
              "refId": "B"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Metrics Exported vs failed /Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "collapsed": false,
          "datasource": "Prometheus",
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 20
          },
          "id": 21,
          "panels": [],
          "repeat": null,
          "title": "Processors",
          "type": "row"
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 8,
            "x": 0,
            "y": 21
          },
          "hiddenSeries": false,
          "id": 10,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "max(otelcol_processor_queued_retry_queue_length)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "Queue Length",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Queued Retry Max Queue Length",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 8,
            "x": 8,
            "y": 21
          },
          "hiddenSeries": false,
          "id": 11,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(otelcol_processor_queued_retry_queue_latency_sum/ otelcol_processor_queued_retry_queue_latency_count)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "ms",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Queued Retry Processor In-queue Latency (ms)",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 8,
            "x": 16,
            "y": 21
          },
          "hiddenSeries": false,
          "id": 32,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(otelcol_processor_queued_retry_send_latency_sum/ otelcol_processor_queued_retry_send_latency_count)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "ms",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Queued Retry Processor Send Latency (ms)",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 0,
            "y": 30
          },
          "hiddenSeries": false,
          "id": 5,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_processor_spans_received{processor=~\"$processor\"}[1m])) by (processor)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{processor}} | received",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_processor_spans_dropped{processor=~\"$processor\"}[1m])) by (processor)",
              "interval": "",
              "legendFormat": "{{processor}} | dropped",
              "refId": "B"
            },
            {
              "expr": "sum(rate(otelcol_processor_accepted_spans{processor=~\"$processor\"}[1m])) by (processor)",
              "interval": "",
              "legendFormat": "{{processor}} | accepted",
              "refId": "C"
            },
            {
              "expr": "sum(rate(otelcol_processor_refused_spans{processor=~\"$processor\"}[1m])) by (processor)",
              "interval": "",
              "legendFormat": "{{processor}} | refused",
              "refId": "E"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Processor Spans Received, Dropped, Accepted, Refused/Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "decimals": null,
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 12,
            "y": 30
          },
          "hiddenSeries": false,
          "id": 14,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_processor_queued_retry_success_send{processor=~\"$processor\"}[1m])) by (processor)",
              "format": "time_series",
              "hide": false,
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{processor}}",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_processor_queued_retry_fail_send{processor=~\"$processor\"}[1m])) by (processor)",
              "interval": "",
              "legendFormat": "{{processor}}",
              "refId": "B"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "QueuedRetry Successful vs Failed Sent/Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 0,
            "y": 39
          },
          "hiddenSeries": false,
          "id": 2,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_processor_spans_received{processor=~\"$processor\"}[1m]) / rate(otelcol_processor_batches_received{processor=~\"$processor\"}[1m])) by (processor)",
              "format": "time_series",
              "hide": false,
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{processor}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Spans per Batch (avg from rates)",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 12,
            "y": 39
          },
          "hiddenSeries": false,
          "id": 12,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(otelcol_processor_batches_received{processor=~\"$processor\"}[1m])) by (processor)",
              "format": "time_series",
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{processor}} | received",
              "refId": "A"
            },
            {
              "expr": "sum(rate(otelcol_processor_trace_batches_dropped{processor=~\"$processor\"}[1m])) by (processor)",
              "interval": "",
              "legendFormat": "{{processor}} | trace dropped",
              "refId": "B"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Batches Received vs Dropped /Second",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 0,
            "y": 48
          },
          "hiddenSeries": false,
          "id": 6,
          "interval": "",
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(otelcol_processor_queued_retry_success_send{processor=~\"$processor\"}) by (processor)",
              "format": "time_series",
              "hide": false,
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{processor}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Successful Batches Sent Cumulative",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": "0",
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 12,
            "y": 48
          },
          "hiddenSeries": false,
          "id": 3,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "links": [],
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 5,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(otelcol_processor_spans_received{exporter=~\"$exporter\"}) by (exporter)",
              "format": "time_series",
              "hide": false,
              "interval": "",
              "intervalFactor": 1,
              "legendFormat": "{{exporter}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Enqueued Spans Cumulative",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "refresh": false,
      "schemaVersion": 25,
      "style": "dark",
      "tags": [
        "opentelemetry"
      ],
      "drt": {
        "list": [
          {
            "allValue": ".*",
            "current": {
              "selected": false,
              "text": "All",
              "value": "$__all"
            },
            "datasource": "Prometheus",
            "definition": "label_values(otelsvc_receiver)",
            "hide": 0,
            "includeAll": true,
            "label": "receiver",
            "multi": true,
            "name": "receiver",
            "options": [],
            "query": "label_values(otelsvc_receiver)",
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          },
          {
            "allValue": ".*",
            "current": {
              "selected": false,
              "text": "All",
              "value": "$__all"
            },
            "datasource": "Prometheus",
            "definition": "label_values(otelsvc_exporter)",
            "hide": 0,
            "includeAll": true,
            "label": "exporter",
            "multi": true,
            "name": "exporter",
            "options": [],
            "query": "label_values(otelsvc_exporter)",
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          },
          {
            "allValue": null,
            "current": {
              "selected": false,
              "text": "All",
              "value": "$__all"
            },
            "datasource": "Prometheus",
            "definition": "label_values(processor)",
            "hide": 0,
            "includeAll": true,
            "label": "processor",
            "multi": true,
            "name": "processor",
            "options": [],
            "query": "label_values(processor)",
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 1,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          }
        ]
      },
      "time": {
        "from": "now-15m",
        "to": "now"
      },
      "timepicker": {
        "refresh_intervals": [
          "10s",
          "30s",
          "1m",
          "5m",
          "15m",
          "30m",
          "1h",
          "2h",
          "1d"
        ],
        "time_options": [
          "5m",
          "15m",
          "1h",
          "6h",
          "12h",
          "24h",
          "2d",
          "7d",
          "30d"
        ]
      },
      "timezone": "",
      "title": "OpenTelemetry Collector",
      "uid": "BKf2sowmj",
      "version": 7
    }
    `}}

{{- end }}

